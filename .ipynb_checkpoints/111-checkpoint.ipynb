{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26da9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccd73414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "DatetimeIndex(['2022-07-02', '2022-07-03', '2022-07-04', '2022-07-09',\n",
      "               '2022-07-10', '2022-07-16', '2022-07-17', '2022-07-23',\n",
      "               '2022-07-24', '2022-07-30',\n",
      "               ...\n",
      "               '2023-05-29', '2023-06-03', '2023-06-04', '2023-06-10',\n",
      "               '2023-06-11', '2023-06-17', '2023-06-18', '2023-06-19',\n",
      "               '2023-06-24', '2023-06-25'],\n",
      "              dtype='datetime64[ns]', length=114, freq=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(251, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"AAPL.csv\",parse_dates=[\"Date\"],index_col=[0])\n",
    "print(df.index.freq)\n",
    "missing_dates = pd.date_range(start=df.index.min(), end=df.index.max()).difference(df.index)\n",
    "print(missing_dates)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a9ad3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Mid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-07-01</th>\n",
       "      <td>139.039993</td>\n",
       "      <td>135.660004</td>\n",
       "      <td>137.349998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-05</th>\n",
       "      <td>141.610001</td>\n",
       "      <td>136.929993</td>\n",
       "      <td>139.269997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-06</th>\n",
       "      <td>144.119995</td>\n",
       "      <td>141.080002</td>\n",
       "      <td>142.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-07</th>\n",
       "      <td>146.550003</td>\n",
       "      <td>143.279999</td>\n",
       "      <td>144.915001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-08</th>\n",
       "      <td>147.550003</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>146.275002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  High         Low         Mid\n",
       "Date                                          \n",
       "2022-07-01  139.039993  135.660004  137.349998\n",
       "2022-07-05  141.610001  136.929993  139.269997\n",
       "2022-07-06  144.119995  141.080002  142.599998\n",
       "2022-07-07  146.550003  143.279999  144.915001\n",
       "2022-07-08  147.550003  145.000000  146.275002"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the specified columns\n",
    "df.drop(columns=[\"Open\", \"Close\", \"Adj Close\", \"Volume\"], inplace=True)\n",
    "\n",
    "# Calculate the midpoint of low and high and save it as 'Mid'\n",
    "df[\"Mid\"] = (df[\"Low\"] + df[\"High\"]) / 2\n",
    "df.to_csv('apple.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d207a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, prediction_size):\n",
    "    train_size = int(len(data) * (1-prediction_size))\n",
    "    train = pd.DataFrame(data[0:train_size])\n",
    "    test = pd.DataFrame(data[train_size:len(data)])\n",
    "    return train, test\n",
    "df_train, df_test = train_test_split(df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b75b2cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n",
      "(51, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16f84753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df_train_scaled = scaler.fit_transform(df_train)\n",
    "df_test_scaled = scaler.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4ffe0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f71b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cbab4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series_data(input_data, history_length):\n",
    "    X_data, Y_data = [], []\n",
    "\n",
    "    for idx in range(history_length, len(input_data)):\n",
    "        X_data.append(input_data[idx-history_length :idx, 0:input_data.shape[1]])\n",
    "#         Y_data.append(input_data[idx, 0:input_data.shape[1]]) #这是沿第二个维度（特征）的切片，从第一个特征开始，到最后一个特征结束。简而言之，我们选择了所有的特征。\n",
    "        Y_data.append(input_data[idx, 0])\n",
    "    return np.array(X_data), np.array(Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1a6b54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34f63867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX Shape--  (195, 5, 3)\n",
      "trainY Shape--  (195,)\n",
      "testX Shape--  (46, 5, 3)\n",
      "testY Shape--  (46,)\n",
      "trainX[0]-- \n",
      " [[0.23294743 0.23472945 0.23048131]\n",
      " [0.28606872 0.26067407 0.27040227]\n",
      " [0.33794955 0.34545465 0.33964027]\n",
      " [0.38817708 0.39039841 0.38777422]\n",
      " [0.40884678 0.42553633 0.4160516 ]]\n",
      "\n",
      "trainY[0]--  0.390037270982055\n"
     ]
    }
   ],
   "source": [
    "trainX,trainY=generate_time_series_data(df_train_scaled,5)\n",
    "testX,testY=generate_time_series_data(df_test_scaled,5)\n",
    "print(\"trainX Shape-- \",trainX.shape) #trainX consists of 1984 time Windows, each consisting of 30 consecutive time steps with 6 features per time step\n",
    "print(\"trainY Shape-- \",trainY.shape)\n",
    "print(\"testX Shape-- \",testX.shape)\n",
    "print(\"testY Shape-- \",testY.shape)\n",
    "print(\"trainX[0]-- \\n\",trainX[0])\n",
    "print(\"\\ntrainY[0]-- \",trainY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e300da3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eq220\\AppData\\Local\\Temp\\ipykernel_44612\\2182992767.py:12: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  grid_model = KerasRegressor(build_fn=build_model,verbose=1,validation_data=(testX,testY))\n"
     ]
    }
   ],
   "source": [
    "def build_model(optimizer):\n",
    "    grid_model = Sequential()\n",
    "    grid_model.add(LSTM(50,return_sequences=True,input_shape=(5,3), activation='relu'))\n",
    "    grid_model.add(Dropout(0.2))\n",
    "    grid_model.add(LSTM(units=50, activation='relu'))\n",
    "#     grid_model.add(Dropout(0.2))\n",
    "    grid_model.add(Dense(units=1))\n",
    "\n",
    "    grid_model.compile(loss = 'mse',optimizer = optimizer)\n",
    "    return grid_model\n",
    "\n",
    "grid_model = KerasRegressor(build_fn=build_model,verbose=1,validation_data=(testX,testY))\n",
    "parameters = {'batch_size' : [16, 32, 64], # , 128, 256, 512\n",
    "              'epochs' : [5, 10, 20], # , 200\n",
    "              'optimizer' : ['adam','Adadelta'] }\n",
    "\n",
    "grid_search  = GridSearchCV(estimator = grid_model,\n",
    "                            param_grid = parameters,\n",
    "                            cv = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51df1cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 37ms/step - loss: 0.2161 - val_loss: 0.9004\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1560 - val_loss: 0.6308\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0891 - val_loss: 0.2930\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0294 - val_loss: 0.0075\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0211 - val_loss: 0.0029\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0133\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 33ms/step - loss: 0.3151 - val_loss: 0.8794\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2217 - val_loss: 0.5515\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0989 - val_loss: 0.1062\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0176 - val_loss: 0.0583\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0284 - val_loss: 0.0123\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0137\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 32ms/step - loss: 0.2495 - val_loss: 1.1939\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2496 - val_loss: 1.1934\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2486 - val_loss: 1.1929\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2505 - val_loss: 1.1924\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2490 - val_loss: 1.1919\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3710\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 33ms/step - loss: 0.3487 - val_loss: 1.1035\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3489 - val_loss: 1.1031\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3469 - val_loss: 1.1027\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3470 - val_loss: 1.1023\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3470 - val_loss: 1.1019\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2333\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 33ms/step - loss: 0.2014 - val_loss: 0.7479\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1126 - val_loss: 0.2929\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0288 - val_loss: 0.0045\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0182 - val_loss: 0.0079\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0117 - val_loss: 0.0322\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0315\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0033\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0107 - val_loss: 0.0126\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0031\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0082\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 62ms/step - loss: 0.2926 - val_loss: 0.7731\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1938 - val_loss: 0.4487\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0852 - val_loss: 0.0882\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0161 - val_loss: 0.0441\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0262 - val_loss: 0.0033\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0577\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.0473\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0075\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0101 - val_loss: 0.0023\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0115 - val_loss: 0.0087\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0112\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 32ms/step - loss: 0.2162 - val_loss: 1.0216\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2149 - val_loss: 1.0214\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2158 - val_loss: 1.0212\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2154 - val_loss: 1.0210\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2156 - val_loss: 1.0208\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2153 - val_loss: 1.0206\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2161 - val_loss: 1.0204\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2155 - val_loss: 1.0202\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2154 - val_loss: 1.0200\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2155 - val_loss: 1.0199\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.3195\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 35ms/step - loss: 0.3552 - val_loss: 1.1403\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3554 - val_loss: 1.1401\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3546 - val_loss: 1.1398\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3544 - val_loss: 1.1396\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3537 - val_loss: 1.1393\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3548 - val_loss: 1.1391\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3546 - val_loss: 1.1388\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3555 - val_loss: 1.1385\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3549 - val_loss: 1.1382\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3533 - val_loss: 1.1380\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2389\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 33ms/step - loss: 0.2081 - val_loss: 0.8244\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1422 - val_loss: 0.4959\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0674 - val_loss: 0.0904\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0947\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0192 - val_loss: 0.0033\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0292\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0063\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0066\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0095\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0281\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0142\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0070 - val_loss: 0.0234\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0227\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0110\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0073 - val_loss: 0.0156\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0290\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0117\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0063 - val_loss: 0.0235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0102\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 2s 34ms/step - loss: 0.3621 - val_loss: 1.0356\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2894 - val_loss: 0.8242\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2111 - val_loss: 0.5676\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1198 - val_loss: 0.1968\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0295 - val_loss: 0.0487\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0284 - val_loss: 0.0144\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0133 - val_loss: 0.0237\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0142\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0032\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0034\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0059\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0105 - val_loss: 0.0071\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0048\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0046\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0086\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0035\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0086\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0111 - val_loss: 0.0080\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0030\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0110 - val_loss: 0.0031\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0115\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 32ms/step - loss: 0.2498 - val_loss: 1.1887\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2493 - val_loss: 1.1884\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2485 - val_loss: 1.1882\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2500 - val_loss: 1.1879\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2494 - val_loss: 1.1877\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2494 - val_loss: 1.1874\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2493 - val_loss: 1.1871\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2487 - val_loss: 1.1869\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2479 - val_loss: 1.1866\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2490 - val_loss: 1.1863\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2486 - val_loss: 1.1861\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2493 - val_loss: 1.1858\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2485 - val_loss: 1.1855\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2483 - val_loss: 1.1853\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2483 - val_loss: 1.1850\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2477 - val_loss: 1.1847\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2484 - val_loss: 1.1844\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2482 - val_loss: 1.1841\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2480 - val_loss: 1.1839\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2483 - val_loss: 1.1836\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3701\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 32ms/step - loss: 0.3414 - val_loss: 1.0858\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3402 - val_loss: 1.0855\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3408 - val_loss: 1.0852\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3402 - val_loss: 1.0848\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3416 - val_loss: 1.0845\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3409 - val_loss: 1.0842\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3400 - val_loss: 1.0839\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3397 - val_loss: 1.0836\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3401 - val_loss: 1.0832\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3390 - val_loss: 1.0829\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3403 - val_loss: 1.0825\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3391 - val_loss: 1.0822\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3390 - val_loss: 1.0819\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3394 - val_loss: 1.0815\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3393 - val_loss: 1.0811\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3382 - val_loss: 1.0808\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3391 - val_loss: 1.0805\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3391 - val_loss: 1.0801\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3387 - val_loss: 1.0798\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3384 - val_loss: 1.0794\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.2280\n",
      "Epoch 1/5\n",
      "4/4 [==============================] - 1s 66ms/step - loss: 0.2526 - val_loss: 1.0748\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2063 - val_loss: 0.8830\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1638 - val_loss: 0.6925\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1211 - val_loss: 0.5040\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0809 - val_loss: 0.3106\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0803\n",
      "Epoch 1/5\n",
      "4/4 [==============================] - 2s 63ms/step - loss: 0.3345 - val_loss: 0.9884\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2886 - val_loss: 0.8628\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2380 - val_loss: 0.7089\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1811 - val_loss: 0.5105\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1128 - val_loss: 0.2804\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0424\n",
      "Epoch 1/5\n",
      "4/4 [==============================] - 1s 64ms/step - loss: 0.2626 - val_loss: 1.2342\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2623 - val_loss: 1.2340\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2637 - val_loss: 1.2338\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2622 - val_loss: 1.2337\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2631 - val_loss: 1.2334\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3866\n",
      "Epoch 1/5\n",
      "4/4 [==============================] - 1s 65ms/step - loss: 0.3331 - val_loss: 1.0693\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3329 - val_loss: 1.0691\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3344 - val_loss: 1.0689\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3330 - val_loss: 1.0687\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3330 - val_loss: 1.0685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2255\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 62ms/step - loss: 0.2314 - val_loss: 0.9631\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1874 - val_loss: 0.7946\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1467 - val_loss: 0.6131\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1072 - val_loss: 0.4222\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0700 - val_loss: 0.2256\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0348 - val_loss: 0.0499\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0136\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0171 - val_loss: 0.0470\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0191 - val_loss: 0.0060\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 0.0116\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 63ms/step - loss: 0.3575 - val_loss: 1.0671\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3196 - val_loss: 0.9776\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2853 - val_loss: 0.8873\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2495 - val_loss: 0.7795\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2074 - val_loss: 0.6456\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1564 - val_loss: 0.4581\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0951 - val_loss: 0.2360\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0402 - val_loss: 0.0487\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 0.0045\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0215 - val_loss: 0.0082\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0278\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 63ms/step - loss: 0.2474 - val_loss: 1.1770\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2471 - val_loss: 1.1768\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2476 - val_loss: 1.1767\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2469 - val_loss: 1.1765\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2466 - val_loss: 1.1764\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2470 - val_loss: 1.1762\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2470 - val_loss: 1.1760\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2468 - val_loss: 1.1759\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2469 - val_loss: 1.1757\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2470 - val_loss: 1.1756\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3679\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 63ms/step - loss: 0.3462 - val_loss: 1.1094\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3464 - val_loss: 1.1092\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3461 - val_loss: 1.1091\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3465 - val_loss: 1.1089\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3460 - val_loss: 1.1088\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3452 - val_loss: 1.1086\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3453 - val_loss: 1.1084\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3467 - val_loss: 1.1083\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3461 - val_loss: 1.1081\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3459 - val_loss: 1.1080\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2338\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 2s 64ms/step - loss: 0.2330 - val_loss: 1.0216\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1995 - val_loss: 0.8862\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1650 - val_loss: 0.7372\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1288 - val_loss: 0.5521\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0858 - val_loss: 0.3432\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0471 - val_loss: 0.1346\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.0057\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0184 - val_loss: 0.0202\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0237 - val_loss: 0.0024\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0188\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 0.0463\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0139 - val_loss: 0.0402\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0028\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 0.0035\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0108 - val_loss: 0.0026\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0090\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0194\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0161\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0040\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0095\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 62ms/step - loss: 0.3099 - val_loss: 0.9052\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2645 - val_loss: 0.7532\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2090 - val_loss: 0.5722\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1427 - val_loss: 0.3451\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0752 - val_loss: 0.1017\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0181 - val_loss: 0.0040\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0212 - val_loss: 0.0141\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.0058\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0106 - val_loss: 0.0344\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0455\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0130 - val_loss: 0.0399\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0116 - val_loss: 0.0249\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0096 - val_loss: 0.0084\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0114\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0108 - val_loss: 0.0144\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 0.0075\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0182\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0111 - val_loss: 0.0198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0124\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 61ms/step - loss: 0.2483 - val_loss: 1.1694\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2476 - val_loss: 1.1692\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2474 - val_loss: 1.1690\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2478 - val_loss: 1.1689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2470 - val_loss: 1.1687\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2474 - val_loss: 1.1686\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2468 - val_loss: 1.1684\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2473 - val_loss: 1.1682\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2469 - val_loss: 1.1680\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2467 - val_loss: 1.1679\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2474 - val_loss: 1.1677\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2473 - val_loss: 1.1675\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2465 - val_loss: 1.1674\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2470 - val_loss: 1.1672\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2477 - val_loss: 1.1671\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2466 - val_loss: 1.1669\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2468 - val_loss: 1.1667\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2465 - val_loss: 1.1665\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2471 - val_loss: 1.1664\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2471 - val_loss: 1.1662\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3651\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 1s 65ms/step - loss: 0.3477 - val_loss: 1.1233\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3479 - val_loss: 1.1231\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3480 - val_loss: 1.1230\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3473 - val_loss: 1.1229\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3476 - val_loss: 1.1228\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3475 - val_loss: 1.1226\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3478 - val_loss: 1.1225\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3474 - val_loss: 1.1224\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3475 - val_loss: 1.1223\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3474 - val_loss: 1.1222\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3475 - val_loss: 1.1221\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3471 - val_loss: 1.1219\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3477 - val_loss: 1.1218\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3465 - val_loss: 1.1216\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3478 - val_loss: 1.1215\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3479 - val_loss: 1.1214\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3469 - val_loss: 1.1213\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3466 - val_loss: 1.1211\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3467 - val_loss: 1.1210\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3462 - val_loss: 1.1209\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2359\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 2s 178ms/step - loss: 0.2326 - val_loss: 1.0594\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2171 - val_loss: 1.0026\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2006 - val_loss: 0.9370\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1838 - val_loss: 0.8622\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1671 - val_loss: 0.7809\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2277\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 188ms/step - loss: 0.3254 - val_loss: 0.9800\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2957 - val_loss: 0.8948\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2646 - val_loss: 0.8017\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2340 - val_loss: 0.7019\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1998 - val_loss: 0.5981\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1130\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 186ms/step - loss: 0.2330 - val_loss: 1.1137\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2328 - val_loss: 1.1136\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2341 - val_loss: 1.1135\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2342 - val_loss: 1.1134\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2334 - val_loss: 1.1133\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3479\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 1s 395ms/step - loss: 0.3950 - val_loss: 1.2723\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3941 - val_loss: 1.2722\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3951 - val_loss: 1.2721\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3933 - val_loss: 1.2720\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3936 - val_loss: 1.2718\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2661\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 185ms/step - loss: 0.2147 - val_loss: 0.9556\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1962 - val_loss: 0.8841\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1773 - val_loss: 0.8032\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1577 - val_loss: 0.7122\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1375 - val_loss: 0.6116\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1164 - val_loss: 0.5049\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0910 - val_loss: 0.3923\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0690 - val_loss: 0.2742\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0472 - val_loss: 0.1557\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0259 - val_loss: 0.0557\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0183\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 185ms/step - loss: 0.3233 - val_loss: 0.9942\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2966 - val_loss: 0.9233\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2709 - val_loss: 0.8505\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2430 - val_loss: 0.7683\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2124 - val_loss: 0.6724\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1788 - val_loss: 0.5699\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1426 - val_loss: 0.4611\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1106 - val_loss: 0.3470\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0767 - val_loss: 0.2320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0479 - val_loss: 0.1237\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0193\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 176ms/step - loss: 0.2187 - val_loss: 1.0405\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2194 - val_loss: 1.0404\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2204 - val_loss: 1.0403\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2191 - val_loss: 1.0402\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2192 - val_loss: 1.0401\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2188 - val_loss: 1.0400\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2182 - val_loss: 1.0399\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2197 - val_loss: 1.0397\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2193 - val_loss: 1.0396\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2186 - val_loss: 1.0395\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3248\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 179ms/step - loss: 0.3664 - val_loss: 1.1687\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3656 - val_loss: 1.1686\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3662 - val_loss: 1.1685\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3667 - val_loss: 1.1684\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3659 - val_loss: 1.1682\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3660 - val_loss: 1.1681\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3653 - val_loss: 1.1680\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3648 - val_loss: 1.1678\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3649 - val_loss: 1.1677\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3659 - val_loss: 1.1676\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2448\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 177ms/step - loss: 0.2368 - val_loss: 1.0743\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2199 - val_loss: 1.0094\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2023 - val_loss: 0.9438\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1864 - val_loss: 0.8782\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1684 - val_loss: 0.8081\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1511 - val_loss: 0.7299\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1324 - val_loss: 0.6367\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1115 - val_loss: 0.5315\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0888 - val_loss: 0.4170\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0666 - val_loss: 0.2951\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0452 - val_loss: 0.1714\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0276 - val_loss: 0.0653\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0153 - val_loss: 0.0060\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0145 - val_loss: 0.0165\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0252 - val_loss: 0.0404\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0287 - val_loss: 0.0295\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0249 - val_loss: 0.0077\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0170 - val_loss: 0.0032\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0139 - val_loss: 0.0154\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0117 - val_loss: 0.0333\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0124\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 178ms/step - loss: 0.3412 - val_loss: 1.0300\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3138 - val_loss: 0.9537\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2877 - val_loss: 0.8767\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2594 - val_loss: 0.7962\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2325 - val_loss: 0.7128\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2025 - val_loss: 0.6228\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1709 - val_loss: 0.5212\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1376 - val_loss: 0.4090\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1042 - val_loss: 0.2897\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0686 - val_loss: 0.1682\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0368 - val_loss: 0.0617\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0159 - val_loss: 0.0047\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0105 - val_loss: 0.0234\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0268 - val_loss: 0.0569\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0372 - val_loss: 0.0408\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0257 - val_loss: 0.0122\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0163 - val_loss: 0.0023\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0096 - val_loss: 0.0287\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0112 - val_loss: 0.0441\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0136\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 177ms/step - loss: 0.1999 - val_loss: 0.9448\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1991 - val_loss: 0.9447\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1997 - val_loss: 0.9445\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1980 - val_loss: 0.9444\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1981 - val_loss: 0.9442\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1988 - val_loss: 0.9441\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1992 - val_loss: 0.9439\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1988 - val_loss: 0.9438\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1988 - val_loss: 0.9436\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1988 - val_loss: 0.9434\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1998 - val_loss: 0.9433\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2005 - val_loss: 0.9431\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1994 - val_loss: 0.9430\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1991 - val_loss: 0.9428\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1985 - val_loss: 0.9426\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1992 - val_loss: 0.9425\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1990 - val_loss: 0.9423\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1987 - val_loss: 0.9422\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1986 - val_loss: 0.9420\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1976 - val_loss: 0.9418\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2951\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 179ms/step - loss: 0.3089 - val_loss: 0.9791\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3074 - val_loss: 0.9790\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3098 - val_loss: 0.9789\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3083 - val_loss: 0.9788\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3081 - val_loss: 0.9787\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3098 - val_loss: 0.9786\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3066 - val_loss: 0.9785\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3097 - val_loss: 0.9784\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3080 - val_loss: 0.9783\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.3083 - val_loss: 0.9782\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3087 - val_loss: 0.9781\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3088 - val_loss: 0.9780\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3075 - val_loss: 0.9779\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3082 - val_loss: 0.9778\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3085 - val_loss: 0.9777\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3074 - val_loss: 0.9775\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3086 - val_loss: 0.9774\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3081 - val_loss: 0.9773\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3078 - val_loss: 0.9772\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3092 - val_loss: 0.9771\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2074\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 1s 18ms/step - loss: 0.1960 - val_loss: 0.3925\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0365 - val_loss: 0.0509\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0168 - val_loss: 0.0541\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0053\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0076\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0037\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0092 - val_loss: 0.0031\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0089 - val_loss: 0.0062\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0082 - val_loss: 0.0025\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0088 - val_loss: 0.0025\n"
     ]
    }
   ],
   "source": [
    "grid_search = grid_search.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec8875c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 16, 'epochs': 10, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f7c4d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 1s 20ms/step - loss: 0.2554 - val_loss: 0.7299\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1075 - val_loss: 0.1410\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0269 - val_loss: 0.0092\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0151 - val_loss: 0.0780\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0153 - val_loss: 0.0095\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0128 - val_loss: 0.0105\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0116 - val_loss: 0.0096\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.0030\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0107 - val_loss: 0.0048\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0085 - val_loss: 0.0027\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Execute grid search\n",
    "# grid_search.fit(trainX, trainY)\n",
    "\n",
    "# Extract best hyperparameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train model using the best hyperparameters\n",
    "best_model = build_model(optimizer=best_params['optimizer'])\n",
    "history = best_model.fit(trainX, trainY, epochs=best_params['epochs'], batch_size=best_params['batch_size'], validation_data=(testX, testY), verbose=1, shuffle=False)\n",
    "\n",
    "# Plot training & validation loss values\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94368e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# 定义超参数空间\n",
    "space  = [Integer(10, 50, name='lstm_neurons'),\n",
    "          Real(0.2, 0.9, name='dropout_rate'),\n",
    "          Real(1e-4, 1e-2, name='learning_rate', prior='log-uniform')]\n",
    "\n",
    "# 定义优化目标函数\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    # 在这里构建您的 LSTM 模型\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(params['lstm_neurons'], input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "    model.add(Dropout(params['dropout_rate']))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=params['learning_rate'])\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "    history = model.fit(trainX, trainY, epochs=20, batch_size=16, validation_data=(testX, testY), verbose=0, shuffle=False)\n",
    "    \n",
    "    # 返回验证损失\n",
    "    return history.history['val_loss'][-1]\n",
    "\n",
    "# 执行贝叶斯优化\n",
    "res = gp_minimize(objective, space, n_calls=50, random_state=0)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best parameters: {}\".format(res.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lstm_neurons = res.x[0]\n",
    "best_dropout_rate = res.x[1]\n",
    "best_learning_rate = res.x[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=best_lstm_neurons, return_sequences=True, input_shape=(trainX.shape[1], trainX.shape[2]), activation='relu'))\n",
    "model.add(Dropout(best_dropout_rate))\n",
    "model.add(LSTM(units=best_lstm_neurons, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = Adam(learning_rate=best_learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "history = model.fit(trainX, trainY, epochs=20, batch_size=16, validation_data=(testX, testY), verbose=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20baf66a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract training and validation loss from the history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6bd796",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(testX)\n",
    "print(\"prediction\\n\", prediction)\n",
    "print(\"\\nPrediction Shape-\",prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5715874",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_copies = np.repeat(prediction, 3, axis=-1)\n",
    "inverse_transformed_datas = scaler.inverse_transform(prediction_copies)\n",
    "# pred=scaler.inverse_transform(prediction_copies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c741d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=scaler.inverse_transform(prediction_copies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_copies_array = np.repeat(testY, 3, axis=-1)\n",
    "\n",
    "original_copies_array.shape\n",
    "\n",
    "original = scaler.inverse_transform(np.reshape(original_copies_array,(len(testY),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5971ee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f357dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_High = pred[:, 0]\n",
    "pred_Low = pred[:, 1]\n",
    "pred_Mid = pred[:, 2]\n",
    "\n",
    "# Adjusting the date_range to match the length of pred_High, pred_Low, and pred_Mid\n",
    "df_test_dropped = df_test.iloc[5:]\n",
    "date = df_test_dropped.index.tolist()\n",
    "\n",
    "# Combining the adjusted data\n",
    "pred_data = pd.DataFrame({\n",
    "    'Date': date,\n",
    "    'pred_High': pred_High,\n",
    "    'pred_Low': pred_Low,\n",
    "    'pred_Mid': pred_Mid\n",
    "})\n",
    "\n",
    "pred_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc664932",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_High = original[:, 0]\n",
    "original_Low = original[:, 1]\n",
    "original_Mid = original[:, 2]\n",
    "\n",
    "# Adjusting the date_range to match the length of pred_High, pred_Low, and pred_Mid\n",
    "df_test_dropped = df_test.iloc[5:]\n",
    "date = df_test_dropped.index.tolist()\n",
    "\n",
    "# Combining the adjusted data\n",
    "original_data = pd.DataFrame({\n",
    "    'Date': date,\n",
    "    'original_High': original_High,\n",
    "    'original_Low': original_Low,\n",
    "    'original_Mid': original_Mid\n",
    "})\n",
    "\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3966af",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(pred_data, original_data, on='Date')\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0d365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating MSE, MAE and RMSE for Low_price, High_price and Mid_price\n",
    "\n",
    "def calculate_metrics(pred, original):\n",
    "    mse = np.mean((np.array(pred) - np.array(original))**2)\n",
    "    mae = np.mean(np.abs(np.array(pred) - np.array(original)))\n",
    "    rmse = np.sqrt(mse)\n",
    "    return mse, mae, rmse\n",
    "\n",
    "low_metrics = calculate_metrics(pred_Low, original_Low)\n",
    "high_metrics = calculate_metrics(pred_High, original_High)\n",
    "mid_metrics = calculate_metrics(pred_Mid, original_Mid)\n",
    "\n",
    "low_metrics, high_metrics, mid_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ef7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates = df.index[-len(original):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7740888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_dates, original, color = 'red', label = 'Real Stock Price')\n",
    "plt.plot(df_dates, pred, color = 'blue', label = 'Predicted  Stock Price')\n",
    "plt.title(' Stock Price Prediction')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(' Stock Price')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c73ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df_dates, pred_High, label='Predicted High', color='red')\n",
    "plt.plot(df_dates, pred_Low, label='Predicted Low', color='blue')\n",
    "plt.plot(df_dates, pred_Mid, label='Predicted Mid', color='green')\n",
    "plt.title('Predicted High, Low, and Mid Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trade_strategy(forecast, real, initial_capital):\n",
    "    capital = initial_capital\n",
    "    shares = 0\n",
    "    buy_dates = []\n",
    "    sell_dates = []\n",
    "\n",
    "    for i in range(len(forecast) - 1):\n",
    "        date = forecast.index[i]\n",
    "        current_price = real[date]\n",
    "        next_price = forecast.iloc[i + 1]\n",
    "\n",
    "        if next_price > current_price and shares == 0:\n",
    "            shares = capital // current_price\n",
    "            capital -= shares * current_price\n",
    "            buy_dates.append(date)\n",
    "\n",
    "        elif next_price < current_price and shares > 0:\n",
    "            capital += shares * current_price\n",
    "            shares = 0\n",
    "            sell_dates.append(date)\n",
    "\n",
    "    if shares > 0:\n",
    "        capital += shares * real.iloc[-1]\n",
    "        sell_dates.append(forecast.index[-1])\n",
    "\n",
    "    return capital, buy_dates, sell_dates\n",
    "\n",
    "\n",
    "pred_price = pred_data.set_index('Date')['pred_Mid']\n",
    "original_price = original_data.set_index('Date')['original_Mid']\n",
    "\n",
    "\n",
    "# Creating pandas Series for pred_Mid and original_Mid\n",
    "# forecast_price = pd.Series(pred_Mid, index=date_range, name='forecast_midpoint')\n",
    "# real_price = pd.Series(original_Mid, index=date_range, name='real_midpoint')\n",
    "\n",
    "# Execute the trading strategy again\n",
    "capital_after_trade, buy_dates, sell_dates = trade_strategy(pred_price, original_price, 100000)\n",
    "\n",
    "print(f\"After implementing the trading strategy, the total capital stands at: ${capital_after_trade:.2f}\")\n",
    "print(f\"We buy stocks on these dates: {buy_dates}\")\n",
    "print(f\"We sell stocks on these dates: {sell_dates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803374ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the original_price to only have dates that are in pred_price\n",
    "filtered_original_prices = original_price[original_price.index.isin(pred_price.index)]\n",
    "\n",
    "# Filter buy and sell dates based on the dates in pred_price\n",
    "filtered_buy_dates = [date for date in buy_dates if date in pred_price.index]\n",
    "filtered_sell_dates = [date for date in sell_dates if date in pred_price.index]\n",
    "filtered_dates = filtered_original_prices.index\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(filtered_dates, filtered_original_prices, label=\"Actual Midpoint\", color=\"blue\", alpha=0.6)\n",
    "\n",
    "# Highlight the buy and sell points\n",
    "plt.scatter(filtered_buy_dates, filtered_original_prices.loc[filtered_buy_dates], color=\"green\", label=\"Buy\", marker=\"^\", alpha=1)\n",
    "plt.scatter(filtered_sell_dates, filtered_original_prices.loc[filtered_sell_dates], color=\"red\", label=\"Sell\", marker=\"v\", alpha=1)\n",
    "\n",
    "# Annotate the buy and sell points\n",
    "for buy_date in filtered_buy_dates:\n",
    "    price = filtered_original_prices.loc[buy_date]\n",
    "    plt.annotate(f\"Buy @ {price:.2f}\", (buy_date, price), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "for sell_date in filtered_sell_dates:\n",
    "    price = filtered_original_prices.loc[sell_date]\n",
    "    plt.annotate(f\"Sell @ {price:.2f}\", (sell_date, price), textcoords=\"offset points\", xytext=(0,-15), ha='center')\n",
    "\n",
    "plt.title(\"Trading Strategy Based on Original Midpoint and Predicted Data\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Midpoint Price\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9db60d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['original_Low'] = merged_data['original_Low'].shift(-1)\n",
    "merged_data['original_High'] = merged_data['original_High'].shift(-1)\n",
    "merged_data['original_Mid'] = merged_data['original_Mid'].shift(-1)\n",
    "\n",
    "def generate_signal(row):\n",
    "    if row['pred_High'] <= row['original_Mid']:\n",
    "        return 'Sell'\n",
    "    elif row['pred_Low'] >= row['original_Mid']:\n",
    "        return 'Buy'\n",
    "    else:\n",
    "        return 'Hold'\n",
    "\n",
    "merged_data['Signal'] = merged_data.apply(generate_signal, axis=1)\n",
    "merged_data[['Date', 'pred_Low', 'pred_High', 'original_Low', 'original_High', 'original_Mid', 'Signal']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578140ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_balance = 100000\n",
    "balance = initial_balance\n",
    "stock_quantity = 0\n",
    "\n",
    "# iloc[:-1] is used to avoid NaN in the last row due to the shift operation earlier\n",
    "for _, row in merged_data.iloc[:-1].iterrows():\n",
    "    if row['Signal'] == 'Buy' and balance > 0:\n",
    "        stock_quantity = balance / row['original_Mid']\n",
    "        balance = 0\n",
    "    elif row['Signal'] == 'Sell' and stock_quantity > 0:\n",
    "        balance = stock_quantity * row['original_Mid']\n",
    "        stock_quantity = 0\n",
    "\n",
    "# balance + value of stocks held, iloc[-2] means use the penultimate day's data (as the last row might contain NaN due to the shift operation)\n",
    "final_wealth = balance + stock_quantity * merged_data['original_Mid'].iloc[-2]\n",
    "final_wealth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59261d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify buy and sell dates\n",
    "buy_dates = merged_data[merged_data['Signal'] == 'Buy']['Date']\n",
    "sell_dates = merged_data[merged_data['Signal'] == 'Sell']['Date']\n",
    "dates = merged_data['Date']\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Forecasted price interval\n",
    "plt.fill_between(dates, merged_data['pred_Low'], merged_data['pred_High'], color='blue', alpha=0.5, label='Forecast Interval')\n",
    "\n",
    "# Actual price interval\n",
    "plt.fill_between(dates, merged_data['original_Low'], merged_data['original_High'], color='red', alpha=0.3, label='Actual Interval')\n",
    "\n",
    "# Buy and sell signals (assuming you have a 'midpoint' column for plotting the signal, if not you might want to use 'original_Mid' or similar)\n",
    "plt.scatter(buy_dates, merged_data[merged_data['Signal'] == 'Buy']['original_Mid'], color='green', marker='^', label='Buy Signal')\n",
    "plt.scatter(sell_dates, merged_data[merged_data['Signal'] == 'Sell']['original_Mid'], color='black', marker='v', label='Sell Signal')\n",
    "\n",
    "plt.title('Forecast vs Actual Price Intervals with Buy/Sell Signals')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad0680d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
