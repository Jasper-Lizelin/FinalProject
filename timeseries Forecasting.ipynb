{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e86681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a416cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "DatetimeIndex(['2022-07-02', '2022-07-03', '2022-07-04', '2022-07-09',\n",
      "               '2022-07-10', '2022-07-16', '2022-07-17', '2022-07-23',\n",
      "               '2022-07-24', '2022-07-30',\n",
      "               ...\n",
      "               '2023-05-29', '2023-06-03', '2023-06-04', '2023-06-10',\n",
      "               '2023-06-11', '2023-06-17', '2023-06-18', '2023-06-19',\n",
      "               '2023-06-24', '2023-06-25'],\n",
      "              dtype='datetime64[ns]', length=114, freq=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(251, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"AAPL.csv\",parse_dates=[\"Date\"],index_col=[0])\n",
    "print(df.index.freq)\n",
    "missing_dates = pd.date_range(start=df.index.min(), end=df.index.max()).difference(df.index)\n",
    "print(missing_dates)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe6f18e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-07-01</th>\n",
       "      <td>136.039993</td>\n",
       "      <td>139.039993</td>\n",
       "      <td>135.660004</td>\n",
       "      <td>138.929993</td>\n",
       "      <td>138.105347</td>\n",
       "      <td>71051600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-05</th>\n",
       "      <td>137.770004</td>\n",
       "      <td>141.610001</td>\n",
       "      <td>136.929993</td>\n",
       "      <td>141.559998</td>\n",
       "      <td>140.719742</td>\n",
       "      <td>73353800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-06</th>\n",
       "      <td>141.350006</td>\n",
       "      <td>144.119995</td>\n",
       "      <td>141.080002</td>\n",
       "      <td>142.919998</td>\n",
       "      <td>142.071655</td>\n",
       "      <td>74064300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-07</th>\n",
       "      <td>143.289993</td>\n",
       "      <td>146.550003</td>\n",
       "      <td>143.279999</td>\n",
       "      <td>146.350006</td>\n",
       "      <td>145.481308</td>\n",
       "      <td>66253700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-08</th>\n",
       "      <td>145.259995</td>\n",
       "      <td>147.550003</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>147.039993</td>\n",
       "      <td>146.167191</td>\n",
       "      <td>64547800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2022-07-01  136.039993  139.039993  135.660004  138.929993  138.105347   \n",
       "2022-07-05  137.770004  141.610001  136.929993  141.559998  140.719742   \n",
       "2022-07-06  141.350006  144.119995  141.080002  142.919998  142.071655   \n",
       "2022-07-07  143.289993  146.550003  143.279999  146.350006  145.481308   \n",
       "2022-07-08  145.259995  147.550003  145.000000  147.039993  146.167191   \n",
       "\n",
       "              Volume  \n",
       "Date                  \n",
       "2022-07-01  71051600  \n",
       "2022-07-05  73353800  \n",
       "2022-07-06  74064300  \n",
       "2022-07-07  66253700  \n",
       "2022-07-08  64547800  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5babdf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-06-26</th>\n",
       "      <td>186.830002</td>\n",
       "      <td>188.050003</td>\n",
       "      <td>185.229996</td>\n",
       "      <td>185.270004</td>\n",
       "      <td>185.270004</td>\n",
       "      <td>48088700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-27</th>\n",
       "      <td>185.889999</td>\n",
       "      <td>188.389999</td>\n",
       "      <td>185.669998</td>\n",
       "      <td>188.059998</td>\n",
       "      <td>188.059998</td>\n",
       "      <td>50730800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28</th>\n",
       "      <td>187.929993</td>\n",
       "      <td>189.899994</td>\n",
       "      <td>187.600006</td>\n",
       "      <td>189.250000</td>\n",
       "      <td>189.250000</td>\n",
       "      <td>51216800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29</th>\n",
       "      <td>189.080002</td>\n",
       "      <td>190.070007</td>\n",
       "      <td>188.940002</td>\n",
       "      <td>189.589996</td>\n",
       "      <td>189.589996</td>\n",
       "      <td>46347300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>191.630005</td>\n",
       "      <td>194.479996</td>\n",
       "      <td>191.259995</td>\n",
       "      <td>193.970001</td>\n",
       "      <td>193.970001</td>\n",
       "      <td>85069600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2023-06-26  186.830002  188.050003  185.229996  185.270004  185.270004   \n",
       "2023-06-27  185.889999  188.389999  185.669998  188.059998  188.059998   \n",
       "2023-06-28  187.929993  189.899994  187.600006  189.250000  189.250000   \n",
       "2023-06-29  189.080002  190.070007  188.940002  189.589996  189.589996   \n",
       "2023-06-30  191.630005  194.479996  191.259995  193.970001  193.970001   \n",
       "\n",
       "              Volume  \n",
       "Date                  \n",
       "2023-06-26  48088700  \n",
       "2023-06-27  50730800  \n",
       "2023-06-28  51216800  \n",
       "2023-06-29  46347300  \n",
       "2023-06-30  85069600  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c028deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, prediction_size):\n",
    "    train_size = int(len(data) * (1-prediction_size))\n",
    "    train = pd.DataFrame(data[0:train_size])\n",
    "    test = pd.DataFrame(data[train_size:len(data)])\n",
    "    return train, test\n",
    "df_train, df_test = train_test_split(df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0b22b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 6)\n",
      "(51, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a86012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df_train_scaled = scaler.fit_transform(df_train)\n",
    "df_test_scaled = scaler.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d33a6b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21009618, 0.23294743, 0.23472945, 0.28083978, 0.27390891,\n",
       "        0.27673588],\n",
       "       [0.24633436, 0.28606872, 0.26067407, 0.33393901, 0.32715747,\n",
       "        0.29450437],\n",
       "       [0.32132393, 0.33794955, 0.34545465, 0.36139711, 0.35469249,\n",
       "        0.29998804],\n",
       "       ...,\n",
       "       [0.80812726, 0.79681712, 0.81001045, 0.81142752, 0.82131397,\n",
       "        0.10952368],\n",
       "       [0.81860066, 0.77759414, 0.81430038, 0.81183109, 0.82172047,\n",
       "        0.04878036],\n",
       "       [0.83975714, 0.81934703, 0.84739527, 0.83686652, 0.84694142,\n",
       "        0.11366441]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "462056c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.83347303, 0.83484931, 0.84514806, 0.86028675, 0.8705351 ,\n",
       "        0.0966631 ],\n",
       "       [0.83954746, 0.82885491, 0.84555674, 0.84050054, 0.85060212,\n",
       "        0.13321731],\n",
       "       [0.81776294, 0.79950398, 0.82369784, 0.8075914 , 0.81744937,\n",
       "        0.17860635],\n",
       "       [0.81671553, 0.78193492, 0.81144032, 0.81385019, 0.82375455,\n",
       "        0.05212536],\n",
       "       [0.82069547, 0.79661024, 0.80817161, 0.78235418, 0.79202519,\n",
       "        0.10433407],\n",
       "       [0.77607871, 0.77532047, 0.78917278, 0.7821521 , 0.79182162,\n",
       "        0.07951824],\n",
       "       [0.82069547, 0.84311706, 0.83799809, 0.87603476, 0.88639961,\n",
       "        0.22927531],\n",
       "       [0.88981996, 0.86978114, 0.89295219, 0.90167556, 0.91223032,\n",
       "        0.15446354],\n",
       "       [0.9063678 , 0.88218277, 0.90847811, 0.89985854, 0.9103998 ,\n",
       "        0.13334465],\n",
       "       [0.92333464, 0.88011599, 0.88600608, 0.87865921, 0.88904345,\n",
       "        0.10210818],\n",
       "       [0.91097612, 0.89189755, 0.87824328, 0.85665243, 0.86687376,\n",
       "        0.23107902],\n",
       "       [0.81441137, 0.81169902, 0.82002048, 0.82313731, 0.83311033,\n",
       "        0.35533491],\n",
       "       [0.94197729, 0.96176124, 0.95178754, 0.98021409, 0.9913506 ,\n",
       "        0.60293749],\n",
       "       [0.97339749, 0.95245994, 0.97936682, 0.97880067, 0.98992658,\n",
       "        0.16027986],\n",
       "       [0.98533731, 0.94605206, 0.96894813, 0.94387243, 0.95473978,\n",
       "        0.07819151],\n",
       "       [0.98470892, 0.95618034, 0.97507659, 0.98001202, 0.99114704,\n",
       "        0.14300456],\n",
       "       [1.00209481, 0.96775531, 0.9805925 , 0.98384811, 0.99501162,\n",
       "        0.11051313],\n",
       "       [0.99727681, 0.95680041, 0.9566906 , 0.96002431, 0.97586616,\n",
       "        0.07951052],\n",
       "       [0.98764147, 0.93923135, 0.96629226, 0.94992942, 0.96568243,\n",
       "        0.01598253],\n",
       "       [0.96313374, 0.93778431, 0.97303387, 0.94992942, 0.96568243,\n",
       "        0.05336565],\n",
       "       [0.95726868, 0.93344355, 0.94484173, 0.96244699, 0.97831015,\n",
       "        0.1756295 ],\n",
       "       [0.9842899 , 0.9811908 , 0.98896848, 1.01009489, 1.02637736,\n",
       "        0.23386292],\n",
       "       [1.05529952, 1.00496083, 1.03718094, 1.01231579, 1.0286178 ,\n",
       "        0.15881034],\n",
       "       [1.00481768, 0.9702359 , 1.00674161, 0.99293346, 1.0090649 ,\n",
       "        0.06463862],\n",
       "       [0.98701309, 0.94274516, 0.9624107 , 0.93963245, 0.95529485,\n",
       "        0.1200264 ],\n",
       "       [0.94428144, 0.9229021 , 0.94688476, 0.94528555, 0.9609977 ,\n",
       "        0.07677602],\n",
       "       [0.97193138, 0.95349318, 0.97078666, 0.96850398, 0.98442045,\n",
       "        0.16101693],\n",
       "       [0.99099302, 0.99214572, 0.99979583, 1.01776681, 1.03411678,\n",
       "        0.15157545],\n",
       "       [1.06723936, 1.05870217, 1.07048033, 1.0555219 , 1.07220412,\n",
       "        0.16029221],\n",
       "       [1.07498957, 1.06614329, 1.0743616 , 1.05451235, 1.07118569,\n",
       "        0.49726897],\n",
       "       [1.08273978, 1.08205873, 1.07783449, 1.11185125, 1.12902916,\n",
       "        0.26014363],\n",
       "       [1.15249265, 1.11637051, 1.12543412, 1.12921448, 1.14654519,\n",
       "        0.20645769],\n",
       "       [1.18600765, 1.18189342, 1.10051069, 1.10155458, 1.11864189,\n",
       "        0.66954498],\n",
       "       [1.13028909, 1.08205873, 1.08804899, 1.09408446, 1.11110603,\n",
       "        0.22885931],\n",
       "       [1.09824052, 1.10458895, 1.08580209, 1.06602067, 1.08279527,\n",
       "        0.20644765],\n",
       "       [1.08692908, 1.09694093, 1.08866215, 1.12154257, 1.13880576,\n",
       "        0.11591731],\n",
       "       [1.16233767, 1.12567181, 1.15342207, 1.12941658, 1.14674907,\n",
       "        0.10554271],\n",
       "       [1.15751999, 1.15998358, 1.16036785, 1.18655338, 1.20438867,\n",
       "        0.14725257],\n",
       "       [1.18956857, 1.1653576 , 1.19039852, 1.17686239, 1.19461239,\n",
       "        0.15230171],\n",
       "       [1.20150807, 1.17031843, 1.18181838, 1.18978383, 1.20764754,\n",
       "        0.17185769],\n",
       "       [1.21386693, 1.21434499, 1.21777333, 1.23137473, 1.24960445,\n",
       "        0.23337282],\n",
       "       [1.27188933, 1.22405977, 1.22778365, 1.20936793, 1.22740399,\n",
       "        0.50969734],\n",
       "       [1.22329293, 1.20566376, 1.23064371, 1.21118495, 1.229237  ,\n",
       "        0.11270815],\n",
       "       [1.23355665, 1.19140162, 1.19346275, 1.18998592, 1.20785142,\n",
       "        0.11052085],\n",
       "       [1.2092586 , 1.22529991, 1.21552612, 1.25136272, 1.26976833,\n",
       "        0.12386998],\n",
       "       [1.24717226, 1.23584135, 1.24290093, 1.24490185, 1.2632506 ,\n",
       "        0.13802488],\n",
       "       [1.27398413, 1.24596961, 1.24739534, 1.21643448, 1.23453272,\n",
       "        0.0995072 ],\n",
       "       [1.25429408, 1.25299723, 1.25638414, 1.27276385, 1.29135778,\n",
       "        0.11989905],\n",
       "       [1.29702542, 1.28420837, 1.2958123 , 1.29678973, 1.31559509,\n",
       "        0.12365002],\n",
       "       [1.32111442, 1.28772249, 1.32318709, 1.30365417, 1.32251994,\n",
       "        0.086067  ],\n",
       "       [1.37452882, 1.37887563, 1.37058225, 1.39208552, 1.41172948,\n",
       "        0.38492743]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a58026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def createXY(dataset,n_past):\n",
    "#     dataX = []\n",
    "#     dataY = []\n",
    "#     for i in range(n_past, len(dataset)):\n",
    "#             dataX.append(dataset[i - n_past:i, 0:dataset.shape[1]])\n",
    "#             dataY.append(dataset[i,0])\n",
    "#     return np.array(dataX),np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a7181c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series_data(input_data, history_length):\n",
    "    X_data, Y_data = [], []\n",
    "\n",
    "    for idx in range(history_length, len(input_data)):\n",
    "        X_data.append(input_data[idx-history_length :idx, 0:input_data.shape[1]])\n",
    "        Y_data.append(input_data[idx, 0]) #这里，对于每个 idx，我们只取第一个特征的值作为输出。这意味着我们正在尝试预测每个时间点的第一个特征的值\n",
    "\n",
    "    return np.array(X_data), np.array(Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06fa55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#假设你只想预测第1、第3和第5个特征（记住，索引是从0开始的）\n",
    "#Y_data.append(input_data[idx, [0, 2, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "487609c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_scaled.shape[1] #总共6列值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18b62d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX,trainY=generate_time_series_data(df_train_scaled,30)\n",
    "testX,testY=generate_time_series_data(df_test_scaled,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdaf6a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX Shape--  (170, 30, 6)\n",
      "trainY Shape--  (170,)\n"
     ]
    }
   ],
   "source": [
    "print(\"trainX Shape-- \",trainX.shape) #trainX consists of 1984 time Windows, each consisting of 30 consecutive time steps with 6 features per time step\n",
    "print(\"trainY Shape-- \",trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c78e7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testX Shape--  (21, 30, 6)\n",
      "testY Shape--  (21,)\n"
     ]
    }
   ],
   "source": [
    "print(\"testX Shape-- \",testX.shape)\n",
    "print(\"testY Shape-- \",testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbf9d2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX[0]-- \n",
      " [[0.21009618 0.23294743 0.23472945 0.28083978 0.27390891 0.27673588]\n",
      " [0.24633436 0.28606872 0.26067407 0.33393901 0.32715747 0.29450437]\n",
      " [0.32132393 0.33794955 0.34545465 0.36139711 0.35469249 0.29998804]\n",
      " [0.36196045 0.38817708 0.39039841 0.43064822 0.42413843 0.23970548]\n",
      " [0.40322568 0.40884678 0.42553633 0.44457891 0.43810811 0.22653927]\n",
      " [0.41181393 0.39003727 0.40061292 0.40076712 0.39417339 0.21568615]\n",
      " [0.41369907 0.42744939 0.42655784 0.42075513 0.41421732 0.32719028]\n",
      " [0.35567666 0.38610999 0.36670068 0.41328499 0.40672621 0.2777701 ]\n",
      " [0.3785086  0.43778424 0.38978556 0.47345046 0.46706093 0.33144987]\n",
      " [0.49790528 0.47726344 0.4909091  0.50777303 0.50147979 0.31693378]\n",
      " [0.51801433 0.49193905 0.46026558 0.44518488 0.438716   0.3567666 ]\n",
      " [0.45894422 0.48491113 0.46455582 0.52453058 0.51828442 0.36881833]\n",
      " [0.5259739  0.53637878 0.53524001 0.5657176  0.55958745 0.22866636]\n",
      " [0.59677418 0.57461785 0.5673137  0.61235626 0.60635713 0.23069775]\n",
      " [0.6154168  0.58929317 0.59734439 0.58691693 0.58084653 0.24296018]\n",
      " [0.58651014 0.56366262 0.5742595  0.5639006  0.55776532 0.14222812]\n",
      " [0.54985325 0.52335677 0.54402465 0.53664457 0.53043324 0.15391942]\n",
      " [0.55655637 0.61099642 0.57180812 0.64142928 0.63551195 0.33515453]\n",
      " [0.64872215 0.61740397 0.6177734  0.65273582 0.64685055 0.3564409 ]\n",
      " [0.73795569 0.74121559 0.72175698 0.75691487 0.75132262 0.51395229]\n",
      " [0.73313771 0.74038862 0.75015328 0.73672509 0.73107605 0.2518668 ]\n",
      " [0.71407636 0.71599854 0.72441285 0.70644042 0.70070606 0.19072137]\n",
      " [0.72957678 0.80239771 0.74729324 0.83000208 0.82461509 0.36515303]\n",
      " [0.83787169 0.81479966 0.82247186 0.82354121 0.8181362  0.15650805]\n",
      " [0.77922092 0.78710234 0.79325852 0.81425407 0.81347324 0.16594644]\n",
      " [0.84541254 0.82761479 0.81777327 0.80456275 0.80374108 0.19357627]\n",
      " [0.79618776 0.78648227 0.79836577 0.8055723  0.80475485 0.21563907]\n",
      " [0.8728528  0.85923939 0.87293153 0.8927923  0.89234177 0.26993552]\n",
      " [0.92270628 0.89334458 0.89928512 0.87764996 0.87713549 0.16943654]\n",
      " [0.91767924 0.91773468 0.92400406 0.9505351  0.95032699 0.25348759]]\n",
      "\n",
      "trainY[0]--  0.9532887286673115\n"
     ]
    }
   ],
   "source": [
    "print(\"trainX[0]-- \\n\",trainX[0])\n",
    "print(\"\\ntrainY[0]-- \",trainY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d165e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42ffe2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eq220\\AppData\\Local\\Temp\\ipykernel_19948\\3563693491.py:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  grid_model = KerasRegressor(build_fn=build_model,verbose=1,validation_data=(testX,testY))\n"
     ]
    }
   ],
   "source": [
    "def build_model(optimizer):\n",
    "    grid_model = Sequential()\n",
    "    grid_model.add(LSTM(50,return_sequences=True,input_shape=(30,6)))\n",
    "    grid_model.add(LSTM(50))\n",
    "    grid_model.add(Dropout(0.2))\n",
    "    grid_model.add(Dense(1))\n",
    "\n",
    "    grid_model.compile(loss = 'mse',optimizer = optimizer)\n",
    "    return grid_model\n",
    "\n",
    "grid_model = KerasRegressor(build_fn=build_model,verbose=1,validation_data=(testX,testY))\n",
    "parameters = {'batch_size' : [ 32, 64], # , 128, 256, 512\n",
    "              'epochs' : [ 50, 100], # , 200\n",
    "              'optimizer' : ['adam','Adadelta'] }\n",
    "\n",
    "grid_search  = GridSearchCV(estimator = grid_model,\n",
    "                            param_grid = parameters,\n",
    "                            cv = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0dff190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: [85, 0.1, 0.008930903019374672]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# 定义超参数空间\n",
    "space  = [Integer(32, 256, name='lstm_neurons'),\n",
    "          Real(0.1, 0.9, name='dropout_rate'),\n",
    "          Real(1e-4, 1e-2, name='learning_rate', prior='log-uniform')]\n",
    "\n",
    "# 定义优化目标函数\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    # 在这里构建您的 LSTM 模型\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(params['lstm_neurons'], input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "    model.add(Dropout(params['dropout_rate']))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=params['learning_rate'])\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "    history = model.fit(trainX, trainY, epochs=50, batch_size=32, validation_data=(testX, testY), verbose=0, shuffle=False)\n",
    "    \n",
    "    # 返回验证损失\n",
    "    return history.history['val_loss'][-1]\n",
    "\n",
    "# 执行贝叶斯优化\n",
    "res = gp_minimize(objective, space, n_calls=50, random_state=0)\n",
    "\n",
    "# 输出最佳参数\n",
    "print(\"Best parameters: {}\".format(res.x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fc54625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 217ms/step - loss: 0.0905 - val_loss: 0.1143\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0454 - val_loss: 0.0233\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0369 - val_loss: 0.1237\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0204 - val_loss: 0.2109\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0349 - val_loss: 0.1894\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0210 - val_loss: 0.1090\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0146 - val_loss: 0.0351\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0144 - val_loss: 0.0101\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0152 - val_loss: 0.0144\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0136 - val_loss: 0.0400\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0122 - val_loss: 0.0588\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0131 - val_loss: 0.0527\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0102 - val_loss: 0.0310\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0109 - val_loss: 0.0130\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0108 - val_loss: 0.0087\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0092 - val_loss: 0.0114\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0236\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0112 - val_loss: 0.0245\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0115 - val_loss: 0.0159\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0081 - val_loss: 0.0122\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0065 - val_loss: 0.0142\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0060 - val_loss: 0.0167\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0079 - val_loss: 0.0128\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0065 - val_loss: 0.0080\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0077 - val_loss: 0.0127\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0070 - val_loss: 0.0139\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0069 - val_loss: 0.0201\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0079 - val_loss: 0.0129\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0060 - val_loss: 0.0175\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0085 - val_loss: 0.0142\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0066 - val_loss: 0.0111\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0072 - val_loss: 0.0121\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0057 - val_loss: 0.0101\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0069 - val_loss: 0.0119\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0061 - val_loss: 0.0094\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0057 - val_loss: 0.0077\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0057 - val_loss: 0.0073\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0092\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0057 - val_loss: 0.0052\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0062 - val_loss: 0.0027\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0051 - val_loss: 0.0080\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0055 - val_loss: 0.0137\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0017\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0050 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0056 - val_loss: 0.0040\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0088\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 212ms/step - loss: 0.2133 - val_loss: 0.4978\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0473 - val_loss: 0.0675\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0464 - val_loss: 0.0531\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0348 - val_loss: 0.1369\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0277 - val_loss: 0.2373\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0288 - val_loss: 0.2574\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0289 - val_loss: 0.2023\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0233 - val_loss: 0.1207\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0158 - val_loss: 0.0649\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0226 - val_loss: 0.0493\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0194 - val_loss: 0.0584\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0160 - val_loss: 0.0871\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0147 - val_loss: 0.1003\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0166 - val_loss: 0.0795\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0155 - val_loss: 0.0500\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0155 - val_loss: 0.0289\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0288\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0137 - val_loss: 0.0437\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0142 - val_loss: 0.0563\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0122 - val_loss: 0.0462\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0141 - val_loss: 0.0303\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0126 - val_loss: 0.0272\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0124 - val_loss: 0.0287\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0136 - val_loss: 0.0362\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0104 - val_loss: 0.0383\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0095 - val_loss: 0.0346\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0281\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0108 - val_loss: 0.0260\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0102 - val_loss: 0.0265\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0114 - val_loss: 0.0295\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0108 - val_loss: 0.0368\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0088 - val_loss: 0.0346\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0100 - val_loss: 0.0169\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0216\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0113 - val_loss: 0.0543\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0107 - val_loss: 0.0665\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0110 - val_loss: 0.0372\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0127 - val_loss: 0.0237\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0132 - val_loss: 0.0461\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0101 - val_loss: 0.0488\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0102 - val_loss: 0.0341\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0118 - val_loss: 0.0276\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0310\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0084 - val_loss: 0.0412\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0109 - val_loss: 0.0381\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0102 - val_loss: 0.0228\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0092 - val_loss: 0.0230\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0082 - val_loss: 0.0246\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0100 - val_loss: 0.0270\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0107 - val_loss: 0.0221\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0070\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 235ms/step - loss: 0.2555 - val_loss: 1.4168\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2582 - val_loss: 1.4147\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2576 - val_loss: 1.4125\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2503 - val_loss: 1.4104\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2445 - val_loss: 1.4083\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2545 - val_loss: 1.4061\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2535 - val_loss: 1.4039\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2500 - val_loss: 1.4017\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2468 - val_loss: 1.3996\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2547 - val_loss: 1.3975\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2505 - val_loss: 1.3953\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2511 - val_loss: 1.3931\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2557 - val_loss: 1.3909\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2474 - val_loss: 1.3888\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2580 - val_loss: 1.3867\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2412 - val_loss: 1.3846\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2521 - val_loss: 1.3823\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2494 - val_loss: 1.3800\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2499 - val_loss: 1.3778\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2477 - val_loss: 1.3756\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2501 - val_loss: 1.3735\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2397 - val_loss: 1.3714\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2548 - val_loss: 1.3692\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2488 - val_loss: 1.3670\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2479 - val_loss: 1.3648\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2430 - val_loss: 1.3627\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2440 - val_loss: 1.3605\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2451 - val_loss: 1.3583\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2405 - val_loss: 1.3561\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2470 - val_loss: 1.3539\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2368 - val_loss: 1.3518\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2394 - val_loss: 1.3496\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2425 - val_loss: 1.3474\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2411 - val_loss: 1.3453\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2433 - val_loss: 1.3430\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2336 - val_loss: 1.3409\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2506 - val_loss: 1.3385\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2415 - val_loss: 1.3364\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2420 - val_loss: 1.3341\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2365 - val_loss: 1.3319\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2425 - val_loss: 1.3297\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2359 - val_loss: 1.3275\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2340 - val_loss: 1.3253\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.2348 - val_loss: 1.3231\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2363 - val_loss: 1.3210\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2416 - val_loss: 1.3187\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2371 - val_loss: 1.3165\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2220 - val_loss: 1.3143\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2379 - val_loss: 1.3121\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2346 - val_loss: 1.3098\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2666\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 2s 211ms/step - loss: 0.3265 - val_loss: 1.5582\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3311 - val_loss: 1.5565\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3240 - val_loss: 1.5548\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3276 - val_loss: 1.5530\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3291 - val_loss: 1.5511\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3211 - val_loss: 1.5494\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3316 - val_loss: 1.5476\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3227 - val_loss: 1.5458\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3168 - val_loss: 1.5439\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3297 - val_loss: 1.5421\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3342 - val_loss: 1.5403\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3188 - val_loss: 1.5385\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3242 - val_loss: 1.5366\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3251 - val_loss: 1.5348\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3245 - val_loss: 1.5329\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3248 - val_loss: 1.5310\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3198 - val_loss: 1.5291\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3270 - val_loss: 1.5272\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3104 - val_loss: 1.5254\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3106 - val_loss: 1.5235\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3154 - val_loss: 1.5217\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3161 - val_loss: 1.5198\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3148 - val_loss: 1.5179\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3121 - val_loss: 1.5161\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3169 - val_loss: 1.5142\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3217 - val_loss: 1.5124\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3190 - val_loss: 1.5104\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3147 - val_loss: 1.5086\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3132 - val_loss: 1.5067\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3131 - val_loss: 1.5048\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3040 - val_loss: 1.5028\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3084 - val_loss: 1.5010\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3123 - val_loss: 1.4990\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3096 - val_loss: 1.4972\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3110 - val_loss: 1.4954\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3058 - val_loss: 1.4935\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3022 - val_loss: 1.4915\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3051 - val_loss: 1.4896\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3033 - val_loss: 1.4877\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3042 - val_loss: 1.4858\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3005 - val_loss: 1.4839\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3039 - val_loss: 1.4819\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3106 - val_loss: 1.4800\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3091 - val_loss: 1.4780\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3041 - val_loss: 1.4761\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.3098 - val_loss: 1.4741\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3020 - val_loss: 1.4722\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3007 - val_loss: 1.4703\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3010 - val_loss: 1.4683\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2966 - val_loss: 1.4663\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2552\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 2s 216ms/step - loss: 0.1969 - val_loss: 0.5096\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0463 - val_loss: 0.0325\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0450 - val_loss: 0.0125\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0342 - val_loss: 0.0740\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0210 - val_loss: 0.1450\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0233 - val_loss: 0.1588\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0236 - val_loss: 0.1148\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0169 - val_loss: 0.0575\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0125 - val_loss: 0.0250\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0135 - val_loss: 0.0144\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0157 - val_loss: 0.0215\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0111 - val_loss: 0.0343\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0129 - val_loss: 0.0414\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0343\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0114 - val_loss: 0.0214\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0111 - val_loss: 0.0122\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0089 - val_loss: 0.0124\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0108 - val_loss: 0.0141\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0093 - val_loss: 0.0195\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0095 - val_loss: 0.0237\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0093 - val_loss: 0.0206\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0093 - val_loss: 0.0127\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0084 - val_loss: 0.0045\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0096 - val_loss: 0.0145\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0264\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0369\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0108 - val_loss: 0.0163\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0083 - val_loss: 0.0098\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0077 - val_loss: 0.0154\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0077 - val_loss: 0.0278\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0077 - val_loss: 0.0276\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0095 - val_loss: 0.0195\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0083 - val_loss: 0.0125\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0064 - val_loss: 0.0156\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0067 - val_loss: 0.0141\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0068 - val_loss: 0.0108\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0058 - val_loss: 0.0195\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0084 - val_loss: 0.0162\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0070 - val_loss: 0.0084\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0058 - val_loss: 0.0102\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0063 - val_loss: 0.0176\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0064 - val_loss: 0.0133\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0063 - val_loss: 0.0119\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0064 - val_loss: 0.0097\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0045 - val_loss: 0.0065\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0048 - val_loss: 0.0113\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0048 - val_loss: 0.0101\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0059 - val_loss: 0.0074\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0060 - val_loss: 0.0084\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0055 - val_loss: 0.0072\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0055 - val_loss: 0.0089\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0042 - val_loss: 0.0075\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0058 - val_loss: 0.0078\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0047 - val_loss: 0.0071\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0052 - val_loss: 0.0012\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0052 - val_loss: 0.0013\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0047 - val_loss: 0.0072\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0050 - val_loss: 0.0117\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0054 - val_loss: 0.0102\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0048 - val_loss: 0.0082\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0048 - val_loss: 0.0067\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0044 - val_loss: 0.0108\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0051 - val_loss: 0.0122\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0045 - val_loss: 0.0065\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0040 - val_loss: 0.0052\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0041 - val_loss: 0.0136\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0047 - val_loss: 0.0015\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0094\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 2s 222ms/step - loss: 0.5770 - val_loss: 1.0496\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1511 - val_loss: 0.2568\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0325 - val_loss: 0.0136\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0751 - val_loss: 0.0091\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0508 - val_loss: 0.0593\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0234 - val_loss: 0.1495\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0193 - val_loss: 0.2178\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0259 - val_loss: 0.2234\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0266 - val_loss: 0.1828\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0219 - val_loss: 0.1211\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0199 - val_loss: 0.0741\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0162 - val_loss: 0.0570\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0152 - val_loss: 0.0583\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0181 - val_loss: 0.0683\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0142 - val_loss: 0.0811\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0155 - val_loss: 0.0887\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0187 - val_loss: 0.0814\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0138 - val_loss: 0.0681\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0145 - val_loss: 0.0537\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0153 - val_loss: 0.0389\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0153 - val_loss: 0.0380\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0132 - val_loss: 0.0459\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0131 - val_loss: 0.0567\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0147 - val_loss: 0.0615\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0138 - val_loss: 0.0531\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0139 - val_loss: 0.0430\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0135 - val_loss: 0.0371\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0138 - val_loss: 0.0352\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0097 - val_loss: 0.0318\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0131 - val_loss: 0.0267\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0120 - val_loss: 0.0279\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0120 - val_loss: 0.0334\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0120 - val_loss: 0.0353\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0106 - val_loss: 0.0325\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0118 - val_loss: 0.0297\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0111 - val_loss: 0.0358\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0113 - val_loss: 0.0340\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0097 - val_loss: 0.0306\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0095 - val_loss: 0.0232\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0116 - val_loss: 0.0224\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0125 - val_loss: 0.0242\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0106 - val_loss: 0.0307\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0094 - val_loss: 0.0311\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0100 - val_loss: 0.0263\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0086 - val_loss: 0.0259\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0328\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0103 - val_loss: 0.0388\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0099 - val_loss: 0.0292\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0100 - val_loss: 0.0278\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0105 - val_loss: 0.0225\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0083 - val_loss: 0.0213\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0094 - val_loss: 0.0251\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0093 - val_loss: 0.0321\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0124 - val_loss: 0.0301\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0192\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0100 - val_loss: 0.0135\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0103 - val_loss: 0.0175\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0081 - val_loss: 0.0251\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0077 - val_loss: 0.0372\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0100 - val_loss: 0.0336\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0094 - val_loss: 0.0244\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0115 - val_loss: 0.0186\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0114 - val_loss: 0.0170\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0125 - val_loss: 0.0290\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0397\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0338\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0089 - val_loss: 0.0306\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0097 - val_loss: 0.0212\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0085 - val_loss: 0.0229\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0106 - val_loss: 0.0223\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0089 - val_loss: 0.0248\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0101 - val_loss: 0.0257\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0084 - val_loss: 0.0184\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0107 - val_loss: 0.0120\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0076 - val_loss: 0.0153\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0078 - val_loss: 0.0173\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0084 - val_loss: 0.0216\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0098 - val_loss: 0.0132\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0147\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0106 - val_loss: 0.0159\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0095 - val_loss: 0.0179\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0079 - val_loss: 0.0137\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0095 - val_loss: 0.0110\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0087 - val_loss: 0.0100\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0093 - val_loss: 0.0152\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0098 - val_loss: 0.0138\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0093 - val_loss: 0.0106\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0104 - val_loss: 0.0075\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0172\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0091 - val_loss: 0.0288\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0088 - val_loss: 0.0236\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0090 - val_loss: 0.0140\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0093 - val_loss: 0.0133\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0087 - val_loss: 0.0231\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0084 - val_loss: 0.0263\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0102 - val_loss: 0.0192\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0080 - val_loss: 0.0070\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0082 - val_loss: 0.0072\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0086 - val_loss: 0.0182\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0063\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 2s 206ms/step - loss: 0.0918 - val_loss: 0.6493\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0914 - val_loss: 0.6483\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0907 - val_loss: 0.6472\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0897 - val_loss: 0.6461\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0857 - val_loss: 0.6450\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0916 - val_loss: 0.6440\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0903 - val_loss: 0.6428\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0863 - val_loss: 0.6418\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0815 - val_loss: 0.6407\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0861 - val_loss: 0.6396\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0882 - val_loss: 0.6385\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0843 - val_loss: 0.6374\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0865 - val_loss: 0.6364\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0859 - val_loss: 0.6353\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0834 - val_loss: 0.6342\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0786 - val_loss: 0.6331\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0910 - val_loss: 0.6320\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0878 - val_loss: 0.6309\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0822 - val_loss: 0.6298\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0812 - val_loss: 0.6287\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0874 - val_loss: 0.6276\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0839 - val_loss: 0.6265\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0865 - val_loss: 0.6254\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0821 - val_loss: 0.6243\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0801 - val_loss: 0.6232\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0804 - val_loss: 0.6222\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0810 - val_loss: 0.6211\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0785 - val_loss: 0.6200\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0826 - val_loss: 0.6189\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0787 - val_loss: 0.6178\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0846 - val_loss: 0.6167\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0814 - val_loss: 0.6156\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0792 - val_loss: 0.6145\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0820 - val_loss: 0.6134\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0902 - val_loss: 0.6123\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0824 - val_loss: 0.6112\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0861 - val_loss: 0.6101\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0875 - val_loss: 0.6090\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0836 - val_loss: 0.6078\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0783 - val_loss: 0.6067\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0781 - val_loss: 0.6056\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0850 - val_loss: 0.6045\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0726 - val_loss: 0.6034\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0800 - val_loss: 0.6023\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0838 - val_loss: 0.6013\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0774 - val_loss: 0.6002\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0699 - val_loss: 0.5991\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0828 - val_loss: 0.5980\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0799 - val_loss: 0.5969\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0802 - val_loss: 0.5958\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0801 - val_loss: 0.5947\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0745 - val_loss: 0.5936\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0761 - val_loss: 0.5925\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0776 - val_loss: 0.5914\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0726 - val_loss: 0.5903\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0789 - val_loss: 0.5892\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0733 - val_loss: 0.5881\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0759 - val_loss: 0.5870\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0749 - val_loss: 0.5859\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0796 - val_loss: 0.5848\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0786 - val_loss: 0.5837\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0717 - val_loss: 0.5826\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0755 - val_loss: 0.5815\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0705 - val_loss: 0.5804\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0719 - val_loss: 0.5794\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0759 - val_loss: 0.5782\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0735 - val_loss: 0.5772\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0700 - val_loss: 0.5760\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0740 - val_loss: 0.5749\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0690 - val_loss: 0.5738\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0714 - val_loss: 0.5727\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0757 - val_loss: 0.5716\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0758 - val_loss: 0.5705\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0749 - val_loss: 0.5693\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0777 - val_loss: 0.5682\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0730 - val_loss: 0.5671\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0693 - val_loss: 0.5660\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0710 - val_loss: 0.5649\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0769 - val_loss: 0.5638\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0748 - val_loss: 0.5626\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0702 - val_loss: 0.5615\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0697 - val_loss: 0.5605\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0694 - val_loss: 0.5594\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0778 - val_loss: 0.5583\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0741 - val_loss: 0.5571\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0776 - val_loss: 0.5560\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0717 - val_loss: 0.5549\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0662 - val_loss: 0.5538\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0778 - val_loss: 0.5527\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0676 - val_loss: 0.5516\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0703 - val_loss: 0.5505\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0635 - val_loss: 0.5494\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0712 - val_loss: 0.5483\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0680 - val_loss: 0.5472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0736 - val_loss: 0.5461\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0620 - val_loss: 0.5451\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0653 - val_loss: 0.5440\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0678 - val_loss: 0.5429\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0656 - val_loss: 0.5418\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0760 - val_loss: 0.5406\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0643\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 2s 215ms/step - loss: 0.2953 - val_loss: 1.3365\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2970 - val_loss: 1.3345\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2886 - val_loss: 1.3325\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3102 - val_loss: 1.3305\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2946 - val_loss: 1.3285\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2919 - val_loss: 1.3265\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2965 - val_loss: 1.3244\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3006 - val_loss: 1.3224\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2860 - val_loss: 1.3204\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2905 - val_loss: 1.3184\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2807 - val_loss: 1.3163\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2894 - val_loss: 1.3143\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2919 - val_loss: 1.3123\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2757 - val_loss: 1.3103\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2843 - val_loss: 1.3083\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2824 - val_loss: 1.3063\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2909 - val_loss: 1.3043\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2782 - val_loss: 1.3023\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2892 - val_loss: 1.3002\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2889 - val_loss: 1.2981\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2924 - val_loss: 1.2960\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2933 - val_loss: 1.2939\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2880 - val_loss: 1.2918\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2892 - val_loss: 1.2898\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2769 - val_loss: 1.2877\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2905 - val_loss: 1.2856\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2900 - val_loss: 1.2835\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2802 - val_loss: 1.2815\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2910 - val_loss: 1.2794\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2789 - val_loss: 1.2773\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2787 - val_loss: 1.2752\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2760 - val_loss: 1.2732\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2727 - val_loss: 1.2710\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2661 - val_loss: 1.2690\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2771 - val_loss: 1.2669\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2812 - val_loss: 1.2648\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2763 - val_loss: 1.2627\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2728 - val_loss: 1.2606\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2855 - val_loss: 1.2585\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2747 - val_loss: 1.2565\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2756 - val_loss: 1.2543\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2856 - val_loss: 1.2522\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2585 - val_loss: 1.2501\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2822 - val_loss: 1.2480\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2657 - val_loss: 1.2458\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2661 - val_loss: 1.2438\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2693 - val_loss: 1.2416\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2615 - val_loss: 1.2396\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2653 - val_loss: 1.2376\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2631 - val_loss: 1.2354\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2640 - val_loss: 1.2334\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2650 - val_loss: 1.2312\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2753 - val_loss: 1.2291\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2592 - val_loss: 1.2270\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2745 - val_loss: 1.2249\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2568 - val_loss: 1.2229\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2556 - val_loss: 1.2208\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2568 - val_loss: 1.2187\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2630 - val_loss: 1.2167\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2564 - val_loss: 1.2146\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2627 - val_loss: 1.2124\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2455 - val_loss: 1.2103\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2614 - val_loss: 1.2082\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2584 - val_loss: 1.2061\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2462 - val_loss: 1.2040\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2679 - val_loss: 1.2019\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2497 - val_loss: 1.1998\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2476 - val_loss: 1.1977\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2598 - val_loss: 1.1955\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2530 - val_loss: 1.1934\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2369 - val_loss: 1.1913\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2462 - val_loss: 1.1891\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2553 - val_loss: 1.1870\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2566 - val_loss: 1.1849\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2653 - val_loss: 1.1827\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2583 - val_loss: 1.1805\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2527 - val_loss: 1.1784\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2575 - val_loss: 1.1763\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2500 - val_loss: 1.1741\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2440 - val_loss: 1.1720\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2481 - val_loss: 1.1699\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2619 - val_loss: 1.1678\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2456 - val_loss: 1.1657\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2295 - val_loss: 1.1637\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2399 - val_loss: 1.1616\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2321 - val_loss: 1.1596\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2343 - val_loss: 1.1575\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2429 - val_loss: 1.1553\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2363 - val_loss: 1.1532\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2290 - val_loss: 1.1511\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2369 - val_loss: 1.1490\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2431 - val_loss: 1.1469\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2403 - val_loss: 1.1447\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2571 - val_loss: 1.1425\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2249 - val_loss: 1.1404\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2211 - val_loss: 1.1383\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2412 - val_loss: 1.1361\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2449 - val_loss: 1.1340\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2398 - val_loss: 1.1318\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2366 - val_loss: 1.1298\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1876\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 626ms/step - loss: 0.3288 - val_loss: 1.0017\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1252 - val_loss: 0.3521\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0363 - val_loss: 0.0393\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0430 - val_loss: 0.0031\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0622 - val_loss: 0.0116\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0472 - val_loss: 0.0572\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0267 - val_loss: 0.1288\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0216 - val_loss: 0.1908\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0262 - val_loss: 0.2215\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0285 - val_loss: 0.2198\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0265 - val_loss: 0.1871\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0264 - val_loss: 0.1365\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0211 - val_loss: 0.0854\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0158 - val_loss: 0.0481\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0178 - val_loss: 0.0263\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0171 - val_loss: 0.0184\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0162 - val_loss: 0.0191\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0165 - val_loss: 0.0273\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0150 - val_loss: 0.0400\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0136 - val_loss: 0.0515\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0156 - val_loss: 0.0579\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0115 - val_loss: 0.0583\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0131 - val_loss: 0.0495\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0131 - val_loss: 0.0340\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0120 - val_loss: 0.0195\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0135 - val_loss: 0.0088\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0108 - val_loss: 0.0133\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0110 - val_loss: 0.0192\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0099 - val_loss: 0.0248\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0097 - val_loss: 0.0263\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0124 - val_loss: 0.0220\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0114 - val_loss: 0.0149\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0102 - val_loss: 0.0084\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0101 - val_loss: 0.0046\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0104 - val_loss: 0.0039\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0111 - val_loss: 0.0042\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0088 - val_loss: 0.0074\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0110 - val_loss: 0.0185\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0093 - val_loss: 0.0292\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0099 - val_loss: 0.0318\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0086 - val_loss: 0.0228\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0079 - val_loss: 0.0114\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0087 - val_loss: 0.0061\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0080 - val_loss: 0.0098\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0069 - val_loss: 0.0137\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0084 - val_loss: 0.0158\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0075 - val_loss: 0.0129\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0078 - val_loss: 0.0096\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0089\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 433ms/step - loss: 0.1636 - val_loss: 0.3712\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0399 - val_loss: 0.0441\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0456 - val_loss: 0.0224\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0540 - val_loss: 0.0756\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0305 - val_loss: 0.1599\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0217 - val_loss: 0.2212\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0274 - val_loss: 0.2304\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0370 - val_loss: 0.1958\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0241 - val_loss: 0.1463\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0204 - val_loss: 0.0974\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0159 - val_loss: 0.0593\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0195 - val_loss: 0.0416\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0172 - val_loss: 0.0424\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0176 - val_loss: 0.0511\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0191 - val_loss: 0.0593\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0186 - val_loss: 0.0652\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0192 - val_loss: 0.0685\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0160 - val_loss: 0.0691\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0135 - val_loss: 0.0680\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0141 - val_loss: 0.0591\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0149 - val_loss: 0.0476\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0137 - val_loss: 0.0412\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0152 - val_loss: 0.0417\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0164 - val_loss: 0.0468\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0154 - val_loss: 0.0529\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0136 - val_loss: 0.0581\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0145 - val_loss: 0.0528\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0155 - val_loss: 0.0415\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0139 - val_loss: 0.0327\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.0147 - val_loss: 0.0334\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0147 - val_loss: 0.0415\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0114 - val_loss: 0.0564\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0115 - val_loss: 0.0624\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0126 - val_loss: 0.0558\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0131 - val_loss: 0.0401\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0096 - val_loss: 0.0233\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0123 - val_loss: 0.0194\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0116 - val_loss: 0.0251\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0126 - val_loss: 0.0389\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0105 - val_loss: 0.0550\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0137 - val_loss: 0.0602\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0120 - val_loss: 0.0510\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0134 - val_loss: 0.0291\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0106 - val_loss: 0.0185\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0129 - val_loss: 0.0200\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0098 - val_loss: 0.0344\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0118 - val_loss: 0.0605\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0122 - val_loss: 0.0679\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0105 - val_loss: 0.0510\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0125 - val_loss: 0.0292\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0074\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 397ms/step - loss: 0.2146 - val_loss: 1.2879\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2151 - val_loss: 1.2866\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2178 - val_loss: 1.2853\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2179 - val_loss: 1.2840\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2131 - val_loss: 1.2828\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2218 - val_loss: 1.2815\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2202 - val_loss: 1.2802\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2196 - val_loss: 1.2788\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2226 - val_loss: 1.2775\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2204 - val_loss: 1.2762\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2148 - val_loss: 1.2750\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2116 - val_loss: 1.2737\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2138 - val_loss: 1.2723\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2199 - val_loss: 1.2709\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2134 - val_loss: 1.2696\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2073 - val_loss: 1.2683\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2093 - val_loss: 1.2670\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2127 - val_loss: 1.2656\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2121 - val_loss: 1.2642\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2166 - val_loss: 1.2628\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2111 - val_loss: 1.2616\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2187 - val_loss: 1.2602\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2074 - val_loss: 1.2588\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2188 - val_loss: 1.2574\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2054 - val_loss: 1.2563\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2183 - val_loss: 1.2547\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2073 - val_loss: 1.2535\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2169 - val_loss: 1.2522\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2146 - val_loss: 1.2508\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2142 - val_loss: 1.2494\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2070 - val_loss: 1.2482\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2110 - val_loss: 1.2468\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2159 - val_loss: 1.2455\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2077 - val_loss: 1.2443\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2129 - val_loss: 1.2428\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2166 - val_loss: 1.2414\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2152 - val_loss: 1.2399\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2141 - val_loss: 1.2385\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2060 - val_loss: 1.2372\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2069 - val_loss: 1.2359\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2063 - val_loss: 1.2344\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2035 - val_loss: 1.2331\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2150 - val_loss: 1.2317\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2168 - val_loss: 1.2304\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2063 - val_loss: 1.2291\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2101 - val_loss: 1.2276\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2075 - val_loss: 1.2262\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2010 - val_loss: 1.2247\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2041 - val_loss: 1.2233\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2055 - val_loss: 1.2219\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2447\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 416ms/step - loss: 0.1523 - val_loss: 0.8548\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1468 - val_loss: 0.8539\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1508 - val_loss: 0.8528\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1585 - val_loss: 0.8519\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1596 - val_loss: 0.8509\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1513 - val_loss: 0.8498\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1504 - val_loss: 0.8488\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1505 - val_loss: 0.8478\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1533 - val_loss: 0.8469\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1528 - val_loss: 0.8459\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1588 - val_loss: 0.8450\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1481 - val_loss: 0.8440\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1525 - val_loss: 0.8430\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1516 - val_loss: 0.8420\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1567 - val_loss: 0.8410\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1453 - val_loss: 0.8400\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1472 - val_loss: 0.8390\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1552 - val_loss: 0.8380\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1503 - val_loss: 0.8370\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1491 - val_loss: 0.8360\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1490 - val_loss: 0.8351\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1517 - val_loss: 0.8341\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1467 - val_loss: 0.8332\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1427 - val_loss: 0.8321\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1566 - val_loss: 0.8310\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1409 - val_loss: 0.8300\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1419 - val_loss: 0.8289\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1489 - val_loss: 0.8280\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1453 - val_loss: 0.8270\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1529 - val_loss: 0.8260\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1408 - val_loss: 0.8250\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1415 - val_loss: 0.8240\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1550 - val_loss: 0.8229\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1454 - val_loss: 0.8220\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1445 - val_loss: 0.8210\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1398 - val_loss: 0.8200\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1549 - val_loss: 0.8190\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1459 - val_loss: 0.8180\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1498 - val_loss: 0.8170\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1484 - val_loss: 0.8160\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1475 - val_loss: 0.8151\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1461 - val_loss: 0.8139\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1408 - val_loss: 0.8129\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1541 - val_loss: 0.8119\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1399 - val_loss: 0.8109\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1396 - val_loss: 0.8099\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1466 - val_loss: 0.8088\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1309 - val_loss: 0.8079\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1485 - val_loss: 0.8068\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1419 - val_loss: 0.8057\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1298\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 439ms/step - loss: 0.2883 - val_loss: 0.8376\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1209 - val_loss: 0.2709\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0350 - val_loss: 0.0252\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0470 - val_loss: 0.0032\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0528 - val_loss: 0.0118\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0332 - val_loss: 0.0541\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0197 - val_loss: 0.1211\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0212 - val_loss: 0.1774\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0221 - val_loss: 0.2004\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0306 - val_loss: 0.1832\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0245 - val_loss: 0.1416\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0194 - val_loss: 0.0954\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0157 - val_loss: 0.0561\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0156 - val_loss: 0.0313\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0175 - val_loss: 0.0205\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0164 - val_loss: 0.0206\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0158 - val_loss: 0.0275\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0130 - val_loss: 0.0373\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0118 - val_loss: 0.0492\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0127 - val_loss: 0.0558\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0126 - val_loss: 0.0578\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0141 - val_loss: 0.0556\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0115 - val_loss: 0.0524\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0128 - val_loss: 0.0438\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0121 - val_loss: 0.0337\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0102 - val_loss: 0.0253\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0110 - val_loss: 0.0200\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0099 - val_loss: 0.0186\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0102 - val_loss: 0.0224\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0096 - val_loss: 0.0301\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0106 - val_loss: 0.0386\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0096 - val_loss: 0.0382\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0102 - val_loss: 0.0306\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0092 - val_loss: 0.0237\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0089 - val_loss: 0.0195\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0087 - val_loss: 0.0205\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0084 - val_loss: 0.0235\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0073 - val_loss: 0.0266\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0087 - val_loss: 0.0273\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0075 - val_loss: 0.0266\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0085 - val_loss: 0.0236\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0071 - val_loss: 0.0159\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0078 - val_loss: 0.0095\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0098 - val_loss: 0.0080\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0075 - val_loss: 0.0109\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0081 - val_loss: 0.0147\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0075 - val_loss: 0.0167\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0072 - val_loss: 0.0157\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0060 - val_loss: 0.0112\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0069 - val_loss: 0.0066\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0075 - val_loss: 0.0044\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0056 - val_loss: 0.0144\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0078 - val_loss: 0.0235\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0069 - val_loss: 0.0213\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0077 - val_loss: 0.0089\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0062 - val_loss: 0.0023\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0069 - val_loss: 0.0054\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0076 - val_loss: 0.0128\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0069 - val_loss: 0.0157\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0063 - val_loss: 0.0115\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0061 - val_loss: 0.0098\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0057 - val_loss: 0.0102\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0053 - val_loss: 0.0042\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0060 - val_loss: 0.0161\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0059 - val_loss: 0.0204\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0071 - val_loss: 0.0094\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0059 - val_loss: 0.0016\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0063 - val_loss: 0.0013\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0057 - val_loss: 0.0238\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0063 - val_loss: 0.0250\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0050 - val_loss: 0.0013\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0064 - val_loss: 0.0012\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0050 - val_loss: 0.0130\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0051 - val_loss: 0.0169\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0050 - val_loss: 0.0095\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0051 - val_loss: 0.0023\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0058 - val_loss: 0.0013\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0067 - val_loss: 0.0022\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0045 - val_loss: 0.0068\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0059 - val_loss: 0.0148\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0052 - val_loss: 0.0165\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0052 - val_loss: 0.0128\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0057 - val_loss: 0.0020\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0053 - val_loss: 0.0013\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0054 - val_loss: 0.0023\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0041 - val_loss: 0.0089\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0109\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 403ms/step - loss: 0.1289 - val_loss: 0.3352\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0314 - val_loss: 0.1044\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0423 - val_loss: 0.1142\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0375 - val_loss: 0.1974\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0276 - val_loss: 0.2781\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0312 - val_loss: 0.3044\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0316 - val_loss: 0.2724\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0293 - val_loss: 0.2122\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0197 - val_loss: 0.1531\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0197 - val_loss: 0.1043\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0201 - val_loss: 0.0789\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0217 - val_loss: 0.0738\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0187 - val_loss: 0.0833\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0149 - val_loss: 0.0958\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0172 - val_loss: 0.0976\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0172 - val_loss: 0.0814\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0142 - val_loss: 0.0556\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0134 - val_loss: 0.0340\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0151 - val_loss: 0.0273\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0133 - val_loss: 0.0340\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0165 - val_loss: 0.0507\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0141 - val_loss: 0.0605\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0121 - val_loss: 0.0611\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0139 - val_loss: 0.0500\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0130 - val_loss: 0.0322\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0100 - val_loss: 0.0213\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0130 - val_loss: 0.0209\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0117 - val_loss: 0.0301\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0112 - val_loss: 0.0409\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0119 - val_loss: 0.0422\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0127 - val_loss: 0.0344\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0142 - val_loss: 0.0272\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0102 - val_loss: 0.0230\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0123 - val_loss: 0.0292\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0106 - val_loss: 0.0480\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0119 - val_loss: 0.0574\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0115 - val_loss: 0.0411\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0108 - val_loss: 0.0240\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0127 - val_loss: 0.0183\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0111 - val_loss: 0.0211\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0095 - val_loss: 0.0371\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0095 - val_loss: 0.0584\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0099 - val_loss: 0.0546\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0125 - val_loss: 0.0384\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0122 - val_loss: 0.0279\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0102 - val_loss: 0.0282\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0133 - val_loss: 0.0301\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0089 - val_loss: 0.0285\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0092 - val_loss: 0.0224\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0113 - val_loss: 0.0156\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0103 - val_loss: 0.0191\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0112 - val_loss: 0.0281\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0081 - val_loss: 0.0326\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0112 - val_loss: 0.0260\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0100 - val_loss: 0.0171\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0087 - val_loss: 0.0204\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0105 - val_loss: 0.0241\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0085 - val_loss: 0.0251\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0071 - val_loss: 0.0262\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0090 - val_loss: 0.0267\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0093 - val_loss: 0.0294\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0089 - val_loss: 0.0395\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0094 - val_loss: 0.0401\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0099 - val_loss: 0.0239\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0086 - val_loss: 0.0154\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0091 - val_loss: 0.0232\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0092 - val_loss: 0.0206\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0091 - val_loss: 0.0172\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0085 - val_loss: 0.0240\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0086 - val_loss: 0.0358\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0093 - val_loss: 0.0292\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0088 - val_loss: 0.0168\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0102 - val_loss: 0.0122\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0093 - val_loss: 0.0223\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0103 - val_loss: 0.0260\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0093 - val_loss: 0.0196\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0077 - val_loss: 0.0166\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0080 - val_loss: 0.0246\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0098 - val_loss: 0.0381\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0108 - val_loss: 0.0330\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0083 - val_loss: 0.0249\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0083 - val_loss: 0.0221\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0086 - val_loss: 0.0174\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0088 - val_loss: 0.0135\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0095 - val_loss: 0.0212\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0088 - val_loss: 0.0324\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0083 - val_loss: 0.0337\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0086 - val_loss: 0.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0088 - val_loss: 0.0094\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0083 - val_loss: 0.0119\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0085 - val_loss: 0.0232\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0101 - val_loss: 0.0183\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0079 - val_loss: 0.0119\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0080 - val_loss: 0.0122\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0074 - val_loss: 0.0173\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0081 - val_loss: 0.0182\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0082 - val_loss: 0.0089\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0095 - val_loss: 0.0064\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0087 - val_loss: 0.0220\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0051\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 413ms/step - loss: 0.1998 - val_loss: 1.1119\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2045 - val_loss: 1.1110\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2069 - val_loss: 1.1101\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2064 - val_loss: 1.1092\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2057 - val_loss: 1.1083\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2091 - val_loss: 1.1073\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2047 - val_loss: 1.1064\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2060 - val_loss: 1.1056\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1985 - val_loss: 1.1047\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2081 - val_loss: 1.1038\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2139 - val_loss: 1.1029\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2014 - val_loss: 1.1019\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2093 - val_loss: 1.1010\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2201 - val_loss: 1.1000\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2067 - val_loss: 1.0990\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2113 - val_loss: 1.0981\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2103 - val_loss: 1.0972\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1995 - val_loss: 1.0962\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2061 - val_loss: 1.0952\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1961 - val_loss: 1.0943\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2065 - val_loss: 1.0933\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2080 - val_loss: 1.0924\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2020 - val_loss: 1.0914\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1955 - val_loss: 1.0905\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2088 - val_loss: 1.0895\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2011 - val_loss: 1.0886\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2047 - val_loss: 1.0876\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2000 - val_loss: 1.0867\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1999 - val_loss: 1.0858\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2081 - val_loss: 1.0849\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2061 - val_loss: 1.0840\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2008 - val_loss: 1.0829\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2000 - val_loss: 1.0821\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2037 - val_loss: 1.0811\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1952 - val_loss: 1.0802\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2015 - val_loss: 1.0793\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1912 - val_loss: 1.0783\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1989 - val_loss: 1.0774\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1942 - val_loss: 1.0764\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1982 - val_loss: 1.0755\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1968 - val_loss: 1.0745\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1929 - val_loss: 1.0735\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1940 - val_loss: 1.0726\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1939 - val_loss: 1.0716\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1924 - val_loss: 1.0707\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1792 - val_loss: 1.0698\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1999 - val_loss: 1.0688\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2007 - val_loss: 1.0679\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1913 - val_loss: 1.0670\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1939 - val_loss: 1.0660\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1955 - val_loss: 1.0651\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2005 - val_loss: 1.0640\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1998 - val_loss: 1.0630\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2004 - val_loss: 1.0621\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1938 - val_loss: 1.0611\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1937 - val_loss: 1.0601\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1985 - val_loss: 1.0592\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1808 - val_loss: 1.0584\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1927 - val_loss: 1.0575\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1890 - val_loss: 1.0565\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.1882 - val_loss: 1.0555\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1885 - val_loss: 1.0546\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1962 - val_loss: 1.0537\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1861 - val_loss: 1.0528\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1836 - val_loss: 1.0517\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2035 - val_loss: 1.0508\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1829 - val_loss: 1.0499\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2005 - val_loss: 1.0490\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1997 - val_loss: 1.0480\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1871 - val_loss: 1.0471\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1948 - val_loss: 1.0462\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1905 - val_loss: 1.0452\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1887 - val_loss: 1.0442\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1946 - val_loss: 1.0431\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1787 - val_loss: 1.0422\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1917 - val_loss: 1.0413\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1877 - val_loss: 1.0403\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1872 - val_loss: 1.0393\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1832 - val_loss: 1.0383\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1794 - val_loss: 1.0374\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1874 - val_loss: 1.0365\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1872 - val_loss: 1.0355\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1838 - val_loss: 1.0345\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1991 - val_loss: 1.0336\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1834 - val_loss: 1.0326\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1855 - val_loss: 1.0316\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1769 - val_loss: 1.0306\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1791 - val_loss: 1.0298\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1826 - val_loss: 1.0287\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1882 - val_loss: 1.0278\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1826 - val_loss: 1.0268\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1857 - val_loss: 1.0259\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1866 - val_loss: 1.0249\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1828 - val_loss: 1.0239\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1855 - val_loss: 1.0229\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1840 - val_loss: 1.0219\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1829 - val_loss: 1.0210\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1843 - val_loss: 1.0199\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1843 - val_loss: 1.0189\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1885 - val_loss: 1.0180\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2128\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 397ms/step - loss: 0.3641 - val_loss: 1.6942\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3772 - val_loss: 1.6929\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3787 - val_loss: 1.6915\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3677 - val_loss: 1.6901\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3627 - val_loss: 1.6887\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3779 - val_loss: 1.6874\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3725 - val_loss: 1.6860\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3637 - val_loss: 1.6847\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3556 - val_loss: 1.6833\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3617 - val_loss: 1.6819\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3701 - val_loss: 1.6805\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3648 - val_loss: 1.6790\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3543 - val_loss: 1.6776\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3795 - val_loss: 1.6762\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3565 - val_loss: 1.6747\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3663 - val_loss: 1.6733\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3628 - val_loss: 1.6719\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3575 - val_loss: 1.6706\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3650 - val_loss: 1.6691\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3653 - val_loss: 1.6678\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3561 - val_loss: 1.6665\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3628 - val_loss: 1.6650\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3603 - val_loss: 1.6636\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3532 - val_loss: 1.6621\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3553 - val_loss: 1.6607\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3402 - val_loss: 1.6594\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3442 - val_loss: 1.6580\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3549 - val_loss: 1.6566\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3535 - val_loss: 1.6552\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3546 - val_loss: 1.6538\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3476 - val_loss: 1.6523\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3504 - val_loss: 1.6509\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3519 - val_loss: 1.6495\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3474 - val_loss: 1.6481\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3558 - val_loss: 1.6467\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3552 - val_loss: 1.6452\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3626 - val_loss: 1.6438\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3396 - val_loss: 1.6424\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3499 - val_loss: 1.6409\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3450 - val_loss: 1.6395\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3397 - val_loss: 1.6382\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3457 - val_loss: 1.6366\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3488 - val_loss: 1.6352\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3480 - val_loss: 1.6338\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3573 - val_loss: 1.6325\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3551 - val_loss: 1.6311\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3473 - val_loss: 1.6295\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3463 - val_loss: 1.6281\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3582 - val_loss: 1.6266\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3347 - val_loss: 1.6252\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3211 - val_loss: 1.6239\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3382 - val_loss: 1.6225\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3524 - val_loss: 1.6210\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3447 - val_loss: 1.6196\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3464 - val_loss: 1.6182\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3444 - val_loss: 1.6166\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3417 - val_loss: 1.6152\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3433 - val_loss: 1.6138\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3484 - val_loss: 1.6123\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3564 - val_loss: 1.6108\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3429 - val_loss: 1.6094\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3437 - val_loss: 1.6079\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3358 - val_loss: 1.6066\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3414 - val_loss: 1.6052\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3325 - val_loss: 1.6038\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3375 - val_loss: 1.6023\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3447 - val_loss: 1.6008\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3491 - val_loss: 1.5994\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3320 - val_loss: 1.5979\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3313 - val_loss: 1.5965\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3528 - val_loss: 1.5950\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3372 - val_loss: 1.5935\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3345 - val_loss: 1.5921\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3523 - val_loss: 1.5905\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3343 - val_loss: 1.5891\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3243 - val_loss: 1.5876\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3230 - val_loss: 1.5861\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3296 - val_loss: 1.5847\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3276 - val_loss: 1.5833\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3323 - val_loss: 1.5819\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3361 - val_loss: 1.5805\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3318 - val_loss: 1.5791\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3342 - val_loss: 1.5776\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3295 - val_loss: 1.5761\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3359 - val_loss: 1.5746\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3288 - val_loss: 1.5731\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3428 - val_loss: 1.5715\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3277 - val_loss: 1.5700\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3261 - val_loss: 1.5685\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3359 - val_loss: 1.5671\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3276 - val_loss: 1.5656\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3251 - val_loss: 1.5641\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3268 - val_loss: 1.5627\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3295 - val_loss: 1.5613\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3315 - val_loss: 1.5598\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3199 - val_loss: 1.5585\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3236 - val_loss: 1.5570\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3279 - val_loss: 1.5555\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3143 - val_loss: 1.5540\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3349 - val_loss: 1.5525\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2612\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 2s 91ms/step - loss: 0.0773 - val_loss: 0.0470\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0287 - val_loss: 0.1989\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0237 - val_loss: 0.1585\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0190 - val_loss: 0.0562\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0178 - val_loss: 0.0551\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0146 - val_loss: 0.0488\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0144 - val_loss: 0.0503\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0113 - val_loss: 0.0340\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.0361\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0115 - val_loss: 0.0212\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0122 - val_loss: 0.0286\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0088 - val_loss: 0.0331\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.0223\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0095 - val_loss: 0.0385\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0097 - val_loss: 0.0209\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0099 - val_loss: 0.0217\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0096 - val_loss: 0.0202\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0092 - val_loss: 0.0210\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0090 - val_loss: 0.0186\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0105 - val_loss: 0.0270\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0087 - val_loss: 0.0098\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0088 - val_loss: 0.0300\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0080 - val_loss: 0.0094\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0082 - val_loss: 0.0217\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 0.0091\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.0197\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0078 - val_loss: 0.0172\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0081 - val_loss: 0.0167\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0072 - val_loss: 0.0144\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0072 - val_loss: 0.0153\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0072 - val_loss: 0.0153\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0078 - val_loss: 0.0135\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0072 - val_loss: 0.0121\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0080 - val_loss: 0.0096\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 0.0144\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0071 - val_loss: 0.0115\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0066 - val_loss: 0.0265\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0074 - val_loss: 0.0076\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0079 - val_loss: 0.0154\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0075 - val_loss: 0.0107\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0073 - val_loss: 0.0028\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0073 - val_loss: 0.0158\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0066 - val_loss: 0.0037\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0084 - val_loss: 0.0203\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0065 - val_loss: 0.0096\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0058 - val_loss: 0.0031\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 0.0073\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0064 - val_loss: 0.0116\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0069 - val_loss: 0.0102\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0063 - val_loss: 0.0130\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0068 - val_loss: 0.0114\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0011\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0053 - val_loss: 0.0188\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0062 - val_loss: 0.0084\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0050 - val_loss: 0.0075\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0051 - val_loss: 0.0085\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 8.6046e-04\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0046 - val_loss: 8.0580e-04\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0048 - val_loss: 0.0093\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0041 - val_loss: 0.0065\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0038 - val_loss: 0.0061\n"
     ]
    }
   ],
   "source": [
    "grid_search = grid_search.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9e26e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32, 'epochs': 100, 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6851ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model=grid_search.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f0b2e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1f699ddc940>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eeb97d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 423ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction=my_model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8699c0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction\n",
      " [[1.0381937]\n",
      " [1.06094  ]\n",
      " [1.0829595]\n",
      " [1.0808984]\n",
      " [1.0550941]\n",
      " [1.0378276]\n",
      " [1.0556695]\n",
      " [1.0835061]\n",
      " [1.119544 ]\n",
      " [1.1315612]\n",
      " [1.1371921]\n",
      " [1.1675972]\n",
      " [1.1708124]\n",
      " [1.1673794]\n",
      " [1.1478287]\n",
      " [1.1759441]\n",
      " [1.1915063]\n",
      " [1.187964 ]\n",
      " [1.2100041]\n",
      " [1.2389774]\n",
      " [1.252516 ]]\n",
      "\n",
      "Prediction Shape- (21, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"prediction\\n\", prediction)\n",
    "print(\"\\nPrediction Shape-\",prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8c654a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3a731d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_copies = np.repeat(prediction, 6, axis=-1)\n",
    "inverse_transformed_data = scaler.inverse_transform(prediction_copies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44862c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_copies_array = np.repeat(prediction, 6, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dbd500f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_copies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b00bd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0381937, 1.0381937, 1.0381937, 1.0381937, 1.0381937, 1.0381937],\n",
       "       [1.06094  , 1.06094  , 1.06094  , 1.06094  , 1.06094  , 1.06094  ],\n",
       "       [1.0829595, 1.0829595, 1.0829595, 1.0829595, 1.0829595, 1.0829595],\n",
       "       [1.0808984, 1.0808984, 1.0808984, 1.0808984, 1.0808984, 1.0808984],\n",
       "       [1.0550941, 1.0550941, 1.0550941, 1.0550941, 1.0550941, 1.0550941],\n",
       "       [1.0378276, 1.0378276, 1.0378276, 1.0378276, 1.0378276, 1.0378276],\n",
       "       [1.0556695, 1.0556695, 1.0556695, 1.0556695, 1.0556695, 1.0556695],\n",
       "       [1.0835061, 1.0835061, 1.0835061, 1.0835061, 1.0835061, 1.0835061],\n",
       "       [1.119544 , 1.119544 , 1.119544 , 1.119544 , 1.119544 , 1.119544 ],\n",
       "       [1.1315612, 1.1315612, 1.1315612, 1.1315612, 1.1315612, 1.1315612],\n",
       "       [1.1371921, 1.1371921, 1.1371921, 1.1371921, 1.1371921, 1.1371921],\n",
       "       [1.1675972, 1.1675972, 1.1675972, 1.1675972, 1.1675972, 1.1675972],\n",
       "       [1.1708124, 1.1708124, 1.1708124, 1.1708124, 1.1708124, 1.1708124],\n",
       "       [1.1673794, 1.1673794, 1.1673794, 1.1673794, 1.1673794, 1.1673794],\n",
       "       [1.1478287, 1.1478287, 1.1478287, 1.1478287, 1.1478287, 1.1478287],\n",
       "       [1.1759441, 1.1759441, 1.1759441, 1.1759441, 1.1759441, 1.1759441],\n",
       "       [1.1915063, 1.1915063, 1.1915063, 1.1915063, 1.1915063, 1.1915063],\n",
       "       [1.187964 , 1.187964 , 1.187964 , 1.187964 , 1.187964 , 1.187964 ],\n",
       "       [1.2100041, 1.2100041, 1.2100041, 1.2100041, 1.2100041, 1.2100041],\n",
       "       [1.2389774, 1.2389774, 1.2389774, 1.2389774, 1.2389774, 1.2389774],\n",
       "       [1.252516 , 1.252516 , 1.252516 , 1.252516 , 1.252516 , 1.252516 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf3108aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=scaler.inverse_transform(prediction_copies)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfe10827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([175.57336, 176.65929, 177.71048, 177.61209, 176.38019, 175.5559 ,\n",
       "       176.40767, 177.73659, 179.45703, 180.03073, 180.29955, 181.75108,\n",
       "       181.90459, 181.74069, 180.80734, 182.14957, 182.8925 , 182.7234 ,\n",
       "       183.7756 , 185.15878, 185.80511], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84f2780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred=scaler.inverse_transform(np.reshape(prediction_copies,(len(prediction),6)))[:,0]\n",
    "# 这是一个数组切片操作，用于选择重塑并进行逆变换后的数组的第一列\n",
    "# 虽然 prediction_copies_array 有6列，但你只对第一列（索引为0的列）感兴趣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ec05dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_copies_array = np.repeat(testY,6, axis=-1)\n",
    "\n",
    "original_copies_array.shape\n",
    "\n",
    "original=scaler.inverse_transform(np.reshape(original_copies_array,(len(testY),6)))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "442e0222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([177.699997, 181.029999, 182.630005, 179.970001, 178.440002,\n",
       "       177.899994, 181.5     , 181.270004, 182.800003, 183.369995,\n",
       "       183.960007, 186.729996, 184.410004, 184.899994, 183.740005,\n",
       "       185.550003, 186.830002, 185.889999, 187.929993, 189.080002,\n",
       "       191.630005])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cecfd7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred Values--  [175.57336 176.65929 177.71048 177.61209 176.38019 175.5559  176.40767\n",
      " 177.73659 179.45703 180.03073 180.29955 181.75108 181.90459 181.74069\n",
      " 180.80734 182.14957 182.8925  182.7234  183.7756  185.15878 185.80511]\n",
      "\n",
      "Original Values--  [177.699997 181.029999 182.630005 179.970001 178.440002 177.899994\n",
      " 181.5      181.270004 182.800003 183.369995 183.960007 186.729996\n",
      " 184.410004 184.899994 183.740005 185.550003 186.830002 185.889999\n",
      " 187.929993 189.080002 191.630005]\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred Values-- \" ,pred)\n",
    "print(\"\\nOriginal Values-- \",original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1986d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07e37414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc371be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates = df.index[-len(original):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bfa9b94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_dates, original, color = 'red', label = 'Real Stock Price')\n",
    "plt.plot(df_dates, pred, color = 'blue', label = 'Predicted  Stock Price')\n",
    "plt.title(' Stock Price Prediction')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(' Stock Price')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441ddb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a095e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_30_days_past=df.iloc[-30:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "451dafea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-05-18</th>\n",
       "      <td>173.000000</td>\n",
       "      <td>175.240005</td>\n",
       "      <td>172.580002</td>\n",
       "      <td>175.050003</td>\n",
       "      <td>175.050003</td>\n",
       "      <td>65496700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-19</th>\n",
       "      <td>176.389999</td>\n",
       "      <td>176.389999</td>\n",
       "      <td>174.940002</td>\n",
       "      <td>175.160004</td>\n",
       "      <td>175.160004</td>\n",
       "      <td>55772400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-22</th>\n",
       "      <td>173.979996</td>\n",
       "      <td>174.710007</td>\n",
       "      <td>173.449997</td>\n",
       "      <td>174.199997</td>\n",
       "      <td>174.199997</td>\n",
       "      <td>43570900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-23</th>\n",
       "      <td>173.130005</td>\n",
       "      <td>173.380005</td>\n",
       "      <td>171.279999</td>\n",
       "      <td>171.559998</td>\n",
       "      <td>171.559998</td>\n",
       "      <td>50747300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-24</th>\n",
       "      <td>171.089996</td>\n",
       "      <td>172.419998</td>\n",
       "      <td>170.520004</td>\n",
       "      <td>171.839996</td>\n",
       "      <td>171.839996</td>\n",
       "      <td>45143500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-25</th>\n",
       "      <td>172.410004</td>\n",
       "      <td>173.899994</td>\n",
       "      <td>171.690002</td>\n",
       "      <td>172.990005</td>\n",
       "      <td>172.990005</td>\n",
       "      <td>56058300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-26</th>\n",
       "      <td>173.320007</td>\n",
       "      <td>175.770004</td>\n",
       "      <td>173.110001</td>\n",
       "      <td>175.429993</td>\n",
       "      <td>175.429993</td>\n",
       "      <td>54835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-30</th>\n",
       "      <td>176.960007</td>\n",
       "      <td>178.990005</td>\n",
       "      <td>176.570007</td>\n",
       "      <td>177.300003</td>\n",
       "      <td>177.300003</td>\n",
       "      <td>55964400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-31</th>\n",
       "      <td>177.330002</td>\n",
       "      <td>179.350006</td>\n",
       "      <td>176.759995</td>\n",
       "      <td>177.250000</td>\n",
       "      <td>177.250000</td>\n",
       "      <td>99625300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-01</th>\n",
       "      <td>177.699997</td>\n",
       "      <td>180.119995</td>\n",
       "      <td>176.929993</td>\n",
       "      <td>180.089996</td>\n",
       "      <td>180.089996</td>\n",
       "      <td>68901800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-02</th>\n",
       "      <td>181.029999</td>\n",
       "      <td>181.779999</td>\n",
       "      <td>179.259995</td>\n",
       "      <td>180.949997</td>\n",
       "      <td>180.949997</td>\n",
       "      <td>61945900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-05</th>\n",
       "      <td>182.630005</td>\n",
       "      <td>184.949997</td>\n",
       "      <td>178.039993</td>\n",
       "      <td>179.580002</td>\n",
       "      <td>179.580002</td>\n",
       "      <td>121946500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-06</th>\n",
       "      <td>179.970001</td>\n",
       "      <td>180.119995</td>\n",
       "      <td>177.429993</td>\n",
       "      <td>179.210007</td>\n",
       "      <td>179.210007</td>\n",
       "      <td>64848400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-07</th>\n",
       "      <td>178.440002</td>\n",
       "      <td>181.210007</td>\n",
       "      <td>177.320007</td>\n",
       "      <td>177.820007</td>\n",
       "      <td>177.820007</td>\n",
       "      <td>61944600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-08</th>\n",
       "      <td>177.899994</td>\n",
       "      <td>180.839996</td>\n",
       "      <td>177.460007</td>\n",
       "      <td>180.570007</td>\n",
       "      <td>180.570007</td>\n",
       "      <td>50214900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-09</th>\n",
       "      <td>181.500000</td>\n",
       "      <td>182.229996</td>\n",
       "      <td>180.630005</td>\n",
       "      <td>180.960007</td>\n",
       "      <td>180.960007</td>\n",
       "      <td>48870700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-12</th>\n",
       "      <td>181.270004</td>\n",
       "      <td>183.889999</td>\n",
       "      <td>180.970001</td>\n",
       "      <td>183.789993</td>\n",
       "      <td>183.789993</td>\n",
       "      <td>54274900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-13</th>\n",
       "      <td>182.800003</td>\n",
       "      <td>184.149994</td>\n",
       "      <td>182.440002</td>\n",
       "      <td>183.309998</td>\n",
       "      <td>183.309998</td>\n",
       "      <td>54929100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-14</th>\n",
       "      <td>183.369995</td>\n",
       "      <td>184.389999</td>\n",
       "      <td>182.020004</td>\n",
       "      <td>183.949997</td>\n",
       "      <td>183.949997</td>\n",
       "      <td>57462900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-15</th>\n",
       "      <td>183.960007</td>\n",
       "      <td>186.520004</td>\n",
       "      <td>183.779999</td>\n",
       "      <td>186.009995</td>\n",
       "      <td>186.009995</td>\n",
       "      <td>65433200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-16</th>\n",
       "      <td>186.729996</td>\n",
       "      <td>186.990005</td>\n",
       "      <td>184.270004</td>\n",
       "      <td>184.919998</td>\n",
       "      <td>184.919998</td>\n",
       "      <td>101235600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-20</th>\n",
       "      <td>184.410004</td>\n",
       "      <td>186.100006</td>\n",
       "      <td>184.410004</td>\n",
       "      <td>185.009995</td>\n",
       "      <td>185.009995</td>\n",
       "      <td>49799100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-21</th>\n",
       "      <td>184.899994</td>\n",
       "      <td>185.410004</td>\n",
       "      <td>182.589996</td>\n",
       "      <td>183.960007</td>\n",
       "      <td>183.960007</td>\n",
       "      <td>49515700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-22</th>\n",
       "      <td>183.740005</td>\n",
       "      <td>187.050003</td>\n",
       "      <td>183.669998</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>51245300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-23</th>\n",
       "      <td>185.550003</td>\n",
       "      <td>187.559998</td>\n",
       "      <td>185.009995</td>\n",
       "      <td>186.679993</td>\n",
       "      <td>186.679993</td>\n",
       "      <td>53079300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-26</th>\n",
       "      <td>186.830002</td>\n",
       "      <td>188.050003</td>\n",
       "      <td>185.229996</td>\n",
       "      <td>185.270004</td>\n",
       "      <td>185.270004</td>\n",
       "      <td>48088700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-27</th>\n",
       "      <td>185.889999</td>\n",
       "      <td>188.389999</td>\n",
       "      <td>185.669998</td>\n",
       "      <td>188.059998</td>\n",
       "      <td>188.059998</td>\n",
       "      <td>50730800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-28</th>\n",
       "      <td>187.929993</td>\n",
       "      <td>189.899994</td>\n",
       "      <td>187.600006</td>\n",
       "      <td>189.250000</td>\n",
       "      <td>189.250000</td>\n",
       "      <td>51216800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-29</th>\n",
       "      <td>189.080002</td>\n",
       "      <td>190.070007</td>\n",
       "      <td>188.940002</td>\n",
       "      <td>189.589996</td>\n",
       "      <td>189.589996</td>\n",
       "      <td>46347300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-06-30</th>\n",
       "      <td>191.630005</td>\n",
       "      <td>194.479996</td>\n",
       "      <td>191.259995</td>\n",
       "      <td>193.970001</td>\n",
       "      <td>193.970001</td>\n",
       "      <td>85069600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2023-05-18  173.000000  175.240005  172.580002  175.050003  175.050003   \n",
       "2023-05-19  176.389999  176.389999  174.940002  175.160004  175.160004   \n",
       "2023-05-22  173.979996  174.710007  173.449997  174.199997  174.199997   \n",
       "2023-05-23  173.130005  173.380005  171.279999  171.559998  171.559998   \n",
       "2023-05-24  171.089996  172.419998  170.520004  171.839996  171.839996   \n",
       "2023-05-25  172.410004  173.899994  171.690002  172.990005  172.990005   \n",
       "2023-05-26  173.320007  175.770004  173.110001  175.429993  175.429993   \n",
       "2023-05-30  176.960007  178.990005  176.570007  177.300003  177.300003   \n",
       "2023-05-31  177.330002  179.350006  176.759995  177.250000  177.250000   \n",
       "2023-06-01  177.699997  180.119995  176.929993  180.089996  180.089996   \n",
       "2023-06-02  181.029999  181.779999  179.259995  180.949997  180.949997   \n",
       "2023-06-05  182.630005  184.949997  178.039993  179.580002  179.580002   \n",
       "2023-06-06  179.970001  180.119995  177.429993  179.210007  179.210007   \n",
       "2023-06-07  178.440002  181.210007  177.320007  177.820007  177.820007   \n",
       "2023-06-08  177.899994  180.839996  177.460007  180.570007  180.570007   \n",
       "2023-06-09  181.500000  182.229996  180.630005  180.960007  180.960007   \n",
       "2023-06-12  181.270004  183.889999  180.970001  183.789993  183.789993   \n",
       "2023-06-13  182.800003  184.149994  182.440002  183.309998  183.309998   \n",
       "2023-06-14  183.369995  184.389999  182.020004  183.949997  183.949997   \n",
       "2023-06-15  183.960007  186.520004  183.779999  186.009995  186.009995   \n",
       "2023-06-16  186.729996  186.990005  184.270004  184.919998  184.919998   \n",
       "2023-06-20  184.410004  186.100006  184.410004  185.009995  185.009995   \n",
       "2023-06-21  184.899994  185.410004  182.589996  183.960007  183.960007   \n",
       "2023-06-22  183.740005  187.050003  183.669998  187.000000  187.000000   \n",
       "2023-06-23  185.550003  187.559998  185.009995  186.679993  186.679993   \n",
       "2023-06-26  186.830002  188.050003  185.229996  185.270004  185.270004   \n",
       "2023-06-27  185.889999  188.389999  185.669998  188.059998  188.059998   \n",
       "2023-06-28  187.929993  189.899994  187.600006  189.250000  189.250000   \n",
       "2023-06-29  189.080002  190.070007  188.940002  189.589996  189.589996   \n",
       "2023-06-30  191.630005  194.479996  191.259995  193.970001  193.970001   \n",
       "\n",
       "               Volume  \n",
       "Date                   \n",
       "2023-05-18   65496700  \n",
       "2023-05-19   55772400  \n",
       "2023-05-22   43570900  \n",
       "2023-05-23   50747300  \n",
       "2023-05-24   45143500  \n",
       "2023-05-25   56058300  \n",
       "2023-05-26   54835000  \n",
       "2023-05-30   55964400  \n",
       "2023-05-31   99625300  \n",
       "2023-06-01   68901800  \n",
       "2023-06-02   61945900  \n",
       "2023-06-05  121946500  \n",
       "2023-06-06   64848400  \n",
       "2023-06-07   61944600  \n",
       "2023-06-08   50214900  \n",
       "2023-06-09   48870700  \n",
       "2023-06-12   54274900  \n",
       "2023-06-13   54929100  \n",
       "2023-06-14   57462900  \n",
       "2023-06-15   65433200  \n",
       "2023-06-16  101235600  \n",
       "2023-06-20   49799100  \n",
       "2023-06-21   49515700  \n",
       "2023-06-22   51245300  \n",
       "2023-06-23   53079300  \n",
       "2023-06-26   48088700  \n",
       "2023-06-27   50730800  \n",
       "2023-06-28   51216800  \n",
       "2023-06-29   46347300  \n",
       "2023-06-30   85069600  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_30_days_past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92497be0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_19948\\3730168045.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdf_30_days_future\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"test.csv\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mparse_dates\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"Date\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mindex_col\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mdf_30_days_future\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Application\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m    910\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    911\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 912\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    913\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    914\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Application\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    575\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    576\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 577\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    578\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    579\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Application\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1405\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1406\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[1;33m|\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1407\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1408\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1409\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Application\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1659\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[1;34m\"b\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1660\u001B[0m                     \u001B[0mmode\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;34m\"b\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1661\u001B[1;33m             self.handles = get_handle(\n\u001B[0m\u001B[0;32m   1662\u001B[0m                 \u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1663\u001B[0m                 \u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Application\\Anaconda\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    857\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;34m\"b\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    858\u001B[0m             \u001B[1;31m# Encoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 859\u001B[1;33m             handle = open(\n\u001B[0m\u001B[0;32m    860\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    861\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'test.csv'"
     ]
    }
   ],
   "source": [
    "df_30_days_future=pd.read_csv(\"test.csv\",parse_dates=[\"Date\"],index_col=[0])\n",
    "df_30_days_future.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7004371c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_30_days_future' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_19948\\4184807080.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdf_30_days_future\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'df_30_days_future' is not defined"
     ]
    }
   ],
   "source": [
    "df_30_days_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20277ef8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_30_days_future' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_19948\\1543418356.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdf_30_days_future\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"Open\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mdf_30_days_future\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdf_30_days_future\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"Open\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m\"High\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m\"Low\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m\"Close\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m\"Adj Close\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mold_scaled_array\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mscaler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_30_days_past\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mnew_scaled_array\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mscaler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_30_days_future\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mold_scaled_df\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mold_scaled_array\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df_30_days_future' is not defined"
     ]
    }
   ],
   "source": [
    "df_30_days_future[\"Open\"]=0\n",
    "df_30_days_future=df_30_days_future[[\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\"]]\n",
    "old_scaled_array=scaler.transform(df_30_days_past)\n",
    "new_scaled_array=scaler.transform(df_30_days_future)\n",
    "old_scaled_df=pd.DataFrame(old_scaled_array)\n",
    "new_scaled_df=pd.DataFrame(new_scaled_array)\n",
    "\n",
    "new_scaled_df.iloc[:,0]=np.nan\n",
    "full_df=pd.concat([old_scaled_df,new_scaled_df]).reset_index().drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0dcb1ee5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_19948\\1445668807.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mfull_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'full_df' is not defined"
     ]
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88cfa224",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_19948\\79004218.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mfull_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtail\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'full_df' is not defined"
     ]
    }
   ],
   "source": [
    "full_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e8cc462a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_19948\\1445668807.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mfull_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'full_df' is not defined"
     ]
    }
   ],
   "source": [
    "full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48bf070f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_19948\\2465155536.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mfull_df_scaled_array\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfull_df\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'full_df' is not defined"
     ]
    }
   ],
   "source": [
    "full_df_scaled_array=full_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "91fdcf82",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_df_scaled_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_19948\\127145115.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mfull_df_scaled_array\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'full_df_scaled_array' is not defined"
     ]
    }
   ],
   "source": [
    "full_df_scaled_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "547622aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_df_scaled_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_19948\\1691912206.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mall_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mtime_step\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m30\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfull_df_scaled_array\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m     \u001B[0mdata_x\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mdata_x\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfull_df_scaled_array\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mtime_step\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mfull_df_scaled_array\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'full_df_scaled_array' is not defined"
     ]
    }
   ],
   "source": [
    "all_data=[]\n",
    "time_step=30\n",
    "for i in range(time_step,len(full_df_scaled_array)):\n",
    "    data_x=[]\n",
    "    data_x.append(full_df_scaled_array[i-time_step:i,0:full_df_scaled_array.shape[1]])\n",
    "    data_x=np.array(data_x)\n",
    "    prediction=my_model.predict(data_x)\n",
    "    all_data.append(prediction)\n",
    "    full_df.iloc[i,0]=prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05929d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "379cf40a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 5)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_19948\\77285878.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;31m#new_array=new_array.reshape(-1,1)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mprediction_copies_array\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew_array\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0my_pred_future_30_days\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mscaler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minverse_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprediction_copies_array\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew_array\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Application\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001B[0m in \u001B[0;36minverse_transform\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    523\u001B[0m         \u001B[0mcheck_is_fitted\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    524\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 525\u001B[1;33m         X = check_array(\n\u001B[0m\u001B[0;32m    526\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mFLOAT_DTYPES\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mforce_all_finite\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"allow-nan\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    527\u001B[0m         )\n",
      "\u001B[1;32m~\\Application\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[0;32m    803\u001B[0m         \u001B[0mn_samples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_num_samples\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    804\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mn_samples\u001B[0m \u001B[1;33m<\u001B[0m \u001B[0mensure_min_samples\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 805\u001B[1;33m             raise ValueError(\n\u001B[0m\u001B[0;32m    806\u001B[0m                 \u001B[1;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    807\u001B[0m                 \u001B[1;34m\" minimum of %d is required%s.\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Found array with 0 sample(s) (shape=(0, 5)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "new_array=np.array(all_data)\n",
    "#new_array=new_array.reshape(-1,1)\n",
    "prediction_copies_array = np.repeat(new_array, 5, axis=-1)\n",
    "y_pred_future_30_days = scaler.inverse_transform(np.reshape(prediction_copies_array,(len(new_array),5)))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ab9307c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_future_30_days' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_19948\\3408788067.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0my_pred_future_30_days\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'y_pred_future_30_days' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred_future_30_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265bfef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eed9c5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ede34e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "my_model.save('Model_future_value.h5')\n",
    "print('Model Saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f12ddc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13f766d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "scalerfile = 'scaler_model_future_value.pkl'\n",
    "pickle.dump(scaler, open(scalerfile, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe5698",
   "metadata": {},
   "source": [
    "# END!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9749107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
